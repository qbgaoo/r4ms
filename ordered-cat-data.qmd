# Ordered categorical data

```{r}
#| echo: false

source("_common.R")
```

## Prerequisites

```{r}
library(tidyverse)
library(ordinal)
library(geepack)
```

::: example
A researcher randomly selected 149 patients who used a pain relief pump after gynecological abdominal surgery. The subjects were randomly divided them into a control group and an treatment group, with different postoperative care methods applied. The researcher observed the patients’ pain at five different time points and assessed the pain levels using a numerical rating scale. The question is whether the two methods differ in their effectiveness in relieving the patients’ pain.
:::

<div>

<a href="datasets/ex18-01.csv" download="ex18-01.csv" class="btn btn-success"> <i class="bi bi-database-fill-down"></i> Download data </a>

</div>

R codes for one-sample *t*-test is:

```{r}
df <- read_csv("datasets/ex18-01.csv", , show_col_types = F) 
```

The pain ratings are categorized as ordinal data, with measurements taken at multiple time points, making it repeated measures data. For such data, the Generalized Estimating Equations (GEE) approach is commonly used. It can handle ordinal data and accounts for the correlation within the data.

下表是模型分析结果：

```{r}
data <- df |> 
  pivot_longer(
    cols = starts_with("t"),
    names_to = "time",
    values_to = "pain",
    names_prefix = "t"
  ) |> 
  mutate(
    subject = as.integer(subject),
    group = factor(group, labels = c("ctrl", "trt")),
    time = as.integer(time)
  )

geeglm(
  pain ~ time + group + time:group, 
  id = subject, 
  corstr = "ar1", 
  data = data
) |> 
  summary()
```

```{r}
ordgee(
  ordered(pain) ~ time + group + time:group, 
  id = subject, 
  corstr = "independence", 
  data = data
) |> 
  summary()
```

模型分析了时间、处理以及时间和处理的交互作用对结果变量（疼痛程度）的影响：

1.  (Intercept)

• Estimate: 2.565 • Standard Error: 0.055 • Statistic: 2,182.131 • p-value: 0.000

Interpretation: The intercept represents the estimated average level of the response variable pain when both time and group are at their reference levels (e.g., at the baseline time point and in the control group). The p-value indicates that this estimate is highly statistically significant, meaning there’s strong evidence that the intercept is different from zero.

2.  time

• Estimate: -0.480 • Standard Error: 0.023 • Statistic: 422.960 • p-value: 0.000

Interpretation: The coefficient for time represents the change in the response variable pain for each unit increase in time (e.g., for each additional time point). The negative estimate suggests that pain decreases over time. This effect is also highly statistically significant (p-value = 0.000).

3.  group (实验组)

• Estimate: -0.304 • Standard Error: 0.090 • Statistic: 11.386 • p-value: 0.001

Interpretation: The coefficient for group (experimental group) indicates the difference in the response variable pain between the experimental group and the reference group (likely the control group). The negative estimate suggests that pain is lower in the experimental group compared to the control group. This difference is statistically significant (p-value = 0.001).

4.  time:group (时间和实验组的交互作用)

• Estimate: 0.038 • Standard Error: 0.035 • Statistic: 1.181 • p-value: 0.277

Interpretation: The interaction term time:group represents how the effect of time on pain differs between the experimental group and the control group. The positive estimate suggests a slight increase in pain over time in the experimental group compared to the control group. However, the p-value of 0.277 indicates that this interaction is not statistically significant, meaning there’s no strong evidence that the effect of time on pain differs between the groups.

Summary

• Main Effects: Both time and group have statistically significant effects on pain. Pain decreases over time and is lower in the experimental group. • Interaction: The interaction between time and group is not statistically significant, suggesting that the rate of change in pain over time does not differ significantly between the experimental and control groups.

```{r}
clm(ordered(pain) ~ time * group, data = data) |> 
  summary()
```

The choice between cumulative link mixed models (CLMM) and generalized estimating equations (GEE) depends on the specifics of your data and the goals of your analysis. Both methods are used for analyzing clustered or repeated measures data with ordinal outcomes, but they have different strengths and weaknesses.

```{r}
clmm(ordered(pain) ~ time * group + (1 | subject), data = data) |> 
  summary()
```

Cumulative Link Mixed Models (CLMM)

Pros:

• Random Effects: CLMMs explicitly model random effects, which allows for subject-specific inferences. This means you can account for the variability between subjects, leading to more accurate estimates of the fixed effects. • Interpretation: CLMMs provide estimates for both fixed effects (population-level effects) and random effects (subject-level variability), which can be useful if you’re interested in understanding both individual and group-level patterns. • Likelihood-Based: CLMMs are likelihood-based models, which can provide more efficient estimates when the model assumptions are met.

Cons:

• Computationally Intensive: CLMMs can be more computationally intensive, especially with large datasets or complex models with many random effects. • Assumptions: CLMMs assume a particular distribution (e.g., normally distributed random effects), and if this assumption is violated, the model may not perform well.

Generalized Estimating Equations (GEE)

Pros:

• Robustness: GEE is robust to misspecification of the correlation structure within clusters. It focuses on estimating population-averaged effects rather than subject-specific effects, which can be more stable when model assumptions are not fully met. • Less Computationally Intensive: GEE tends to be less computationally demanding compared to CLMM, making it a better choice for large datasets. • Flexibility: GEE can handle various types of correlation structures, making it flexible for different kinds of clustered data.

Cons:

• No Random Effects: GEE does not model random effects, which means it does not provide subject-specific inferences. It’s primarily focused on population-averaged effects. • Less Efficient with Small Samples: GEE might be less efficient with small sample sizes compared to CLMM because it does not fully account for subject-level variability.

When to Choose Which:

• Use CLMM if you are interested in subject-specific inferences, need to account for random effects, and are working with a relatively smaller dataset where computational demands are manageable. • Use GEE if you are more interested in population-averaged effects, have a large dataset, or want a method that is more robust to correlation structure misspecification.

In summary, if your primary interest is in understanding individual-level variability and you can handle the computational load, CLMM might be the better choice. If you’re more interested in population-level trends and want a more robust approach with less concern for the specific correlation structure, GEE would be a better option.

ordgee and geeglm are both functions in R used to fit models for clustered or repeated measures data, but they differ in the types of data they handle and the specific models they fit.

ordgee (Ordinal Generalized Estimating Equations)

• Purpose: ordgee is specifically designed for fitting Generalized Estimating Equations (GEE) models to ordinal response data. This is useful when your outcome variable is ordinal (e.g., Likert scale data, ordered categorical data) and you have repeated measures or clustered data. • Model: ordgee accounts for the ordinal nature of the data by using a cumulative logit link function or other appropriate link functions for ordinal outcomes. • Usage: It’s particularly used in situations where the response variable has a natural order but the distances between the categories are not assumed to be equal. It extends the GEE framework to handle the special case of ordinal outcomes. • Example Scenario: If you’re analyzing patient satisfaction scores (e.g., 1 to 5) collected at multiple time points for different treatment groups, ordgee would be appropriate.

geeglm (Generalized Estimating Equations for Generalized Linear Models)

• Purpose: geeglm is a more general function that fits Generalized Estimating Equations (GEE) models for a wide variety of outcome distributions (e.g., Gaussian, binomial, Poisson). It is not restricted to ordinal data and can handle any type of response variable (continuous, binary, count, etc.) that can be modeled with a generalized linear model (GLM). • Model: geeglm allows you to specify the link function and the error distribution appropriate for your data (e.g., logit for binary outcomes, identity for continuous outcomes). It estimates population-averaged effects rather than subject-specific effects. • Usage: It’s used for a broad range of data types and is versatile for many different kinds of clustered or repeated measures data. • Example Scenario: If you’re analyzing binary outcomes (e.g., success/failure) collected at multiple time points across different clusters (e.g., hospitals), geeglm would be the appropriate choice.

Key Differences:

1.  Outcome Type: • ordgee: Specifically for ordinal outcomes. • geeglm: For a wide range of outcome types (continuous, binary, count, etc.).
2.  Link Functions: • ordgee: Uses link functions appropriate for ordinal data (e.g., cumulative logit). • geeglm: Allows specification of various link functions depending on the distribution of the response variable.
3.  Flexibility: • ordgee: More specialized, focusing on ordinal outcomes. • geeglm: More flexible, applicable to various types of response variables.
4.  Interpretation: • ordgee: Focuses on the odds of being in a higher versus lower category of the ordinal outcome. • geeglm: Focuses on population-averaged effects across the levels of the outcome.

When to Use Which:

• Use ordgee when you have ordinal response data and need to account for repeated measures or clustering. • Use geeglm when your response variable is not ordinal, or you are dealing with binary, continuous, or count data, and you need to account for repeated measures or clustering.
