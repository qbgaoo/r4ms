# Sample size estimation

```{r}
#| echo: false
source("_common.R")
```

Sample size estimation is an important step when conducting clinical trials, survey studies, or other scientific research. It is essential for designing a study that is capable of detecting significant effects or differences. A reasonable sample size ensures that the study has sufficient statistical power to detect the effects of interest while avoiding unnecessary waste of resources.

## Prerequisites

```{r}
#| message: false
library(tidyverse)
library(pwr)
library(effectsize)
library(powerSurvEpi)
library(rpact)
```

## Experimental studies

The required sample size in a experimental study is influenced by several key factors, which determine how large a sample is necessary to detect meaningful effects or differences. Here are the primary factors affecting sample size:

**1. Effect size**

Effect size is the magnitude of the difference or relationship the study aims to detect. Larger effect sizes require smaller sample sizes to detect, while smaller effect sizes require larger sample sizes to achieve the same power.

**2. Significance level (**$\alpha$**)**

Significance level is the probability of rejecting the null hypothesis when it is actually true (type I error), often set at 0.05. Lowering $\alpha$ (making the test more stringent) increases the required sample size because it reduces the chance of falsely detecting a significant effect.

**3. Statistical power (**$1-\beta$**)**

Statistical power is the probability of correctly rejecting the null hypothesis when it is false, typically set at 0.8 or 0.9. Higher power requires a larger sample size, as it reduces the chance of a type II error (failing to detect a true effect).

**4. Population variability**

The extent of variability or dispersion in the population, often reflected in standard deviation or variance. Higher variability necessitates a larger sample size to achieve a reliable estimate, as more variability makes it harder to detect true differences.

**5. Study design**

Study design refers to the structure of the study, such as whether it includes repeated measures, matched pairs, or independent groups. Designs that control for variability (e.g., paired designs) generally require smaller sample sizes than independent designs.

**6. Sampling method**

Sampling method refers to the approach of how participants are selected for the study (e.g., random sampling, stratified sampling). A sampling method that better represents the population can improve accuracy and reduce the sample size needed.

**7. Attrition or dropout rate**

Attrition rate denotes the expected rate at which participants may leave the study before it is completed. Higher expected dropout rates require oversampling to ensure adequate final sample size.

Understanding these factors allows researchers to plan a sample size that balances feasibility with statistical rigor, ensuring the study’s findings are reliable and valid. Here’s a breakdown of sample size estimation methods for different study types and analysis.

### Comparison of means

**1. One-sample mean**

To compare a single sample mean with a known population mean, the one-sample t-test is commonly used if the population variance is unknown and the sample size is relatively small. To estimate the required sample size of one-sample t-test, we need to consider several key factors:effect size $\Delta$, significance level $\alpha$, power 1-β, and population standard deviation $\sigma$ (or an estimate if unknown). The sample size $n$ can be estimated as:

$$
n = \left( \frac{Z_{1-\alpha/2} + Z_{1-\beta}}{\Delta / \sigma} \right)^2
$$

where $Z_{1-\alpha/2}$ is the Z-score for the significance level (two-tailed, if applicable), $Z_{1-\beta}$ is the Z-score for the desired power level.

::: example
A scientist wants to study the effect of a treatment on blood pressure in rats with acute myocardial ischemia. It is hypothesized that an average increase of 10 mmHg in arterial systolic pressure would be clinically significant. Given that the standard deviation of the treatment effect on blood pressure is 15 mmHg, how many rats are needed to detect this effect?
:::

The `power.t.test()` function fro the `stats` package can be used to estimate the sample size needed for a one-sample t-test.

```{r}
power.t.test(
  delta = 10, sd = 15, sig.level = 0.05, power = 0.9,
  type = "one.sample", alternative = "one.sided")
```

Alternatively, you can use the `pwr.t.test()` function from the `pwr` package:

```{r}
pwr.t.test(
  d = 10 / 15, sig.level = 0.05, power = 0.9,
  type = "one.sample",alternative = "greater") 
```

Based on the results, the scientist would need 21 rats in order to have a 90% probability of detecting a significant increase in blood pressure of at least 10 mmHg with a one-sided test at a 5% significance level.

**2. Two-sample means**

A two-sample mean comparison is used to determine if there is a significant difference between the means of two independent groups. This type of test is commonly applied in scenarios like comparing the effect of two treatments or comparing measurements between two different populations. To estimate the sample size, we use a formula that considers the effect size, significance level, power, and variability within each group. This is typically done for a two-sample t-test.

The formula for estimating the required sample size $n$ per group is:

$$
n = \frac{2 \sigma^2 (Z_{1-\alpha/2} + Z_{1-\beta})^2}{\Delta^2}
$$

where $\sigma$ is the pooled standard deviation of the two groups, assumed to be the same for both groups (or an estimate from previous data), $Z_{1-\alpha/2}$ is the Z-score corresponding to the chosen significance level (this is often 1.96 if $\alpha = 0.05$), $Z_{1-\beta}$ is the Z-score corresponding to the desired power level (0.84 for 80% power or 1.28 for 90% power), $\Delta$ is the effect size, defined as the minimum detectable difference in means between the two groups.

::: example
A scientist intends to evaluate the efficacy of a compound hypoglycemic capsule on diabetic mice. The plan is to randomly divide diabetic model mice into two equal groups. After four weeks, fasting blood glucose levels will be measured and compared between the two groups. Based on preliminary results, the expected fasting blood glucose in the control group is 16.5 mmol/L, while in the experimental group, it is 10.5 mmol/L. The standard deviation of fasting blood glucose in both groups is assumed to be equal, at 8.0 mmol/L. To detect a significant effect of the compound hypoglycemic capsule, with a significance level of $\alpha = 0.05$ and power of $1 - \beta = 0.90$, how many mice are required in each group?
:::

The `power.t.test()` function and `pwr.t.test()` function can perform this calculation for a two-sample t-test:

```{r}
power.t.test(delta = 6, sd = 8, sig.level = 0.05, power = 0.9, type = "two.sample")
```

```{r}
power.htest <- pwr.t.test(
  d = 6 / 8, sig.level = 0.05, power = 0.9,
  type = "two.sample",alternative = "two.sided") 

power.htest
power.htest |> plot()
```

With these parameters, the output suggests that 39 mice each group are needed to reliably detect a significant difference in fasting blood glucose levels between the treatment and control groups.

**3. Multiple sample means**

When comparing multiple sample means, typically a one-way analysis of variance (ANOVA) is used to test if there are statistically significant differences among the means of three or more independent groups. The one-way ANOVA works under the assumption that the groups have approximately equal variances and that the data are normally distributed within each group.

When comparing multiple sample means with ANOVA, the sample size estimation considers the desired power, significance level, number of groups, and effect size. For a one-way ANOVA with $k$ groups, the sample size $n$ required each group can be estimated using:

$$
n = \frac{2 (Z_{1 - \alpha/2} + Z_{1 - \beta})^2}{f^2}
$$

where $Z_{1 - \alpha/2}$ is the critical value from the standard normal distribution for a two-sided test, $Z_{1 - \beta}$ is the critical value associated with the desired power, $f$, i.e. Cohen’s f, is the effect size for ANOVA, defined as:

$$
f = \frac{\sqrt{\frac{\sum_{i=1}^k (\bar{X}_i - \bar{X}_{\text{grand}})^2}{k}}}{\sigma}
$$

where $k$ is the number of groups, $\bar{X}_i$ is the mean of the $i$-th group,$\bar{X}_{\text{grand}}$ is the overall (grand) mean across all groups, and $\sigma$ is the pooled within-group standard deviation, which is expressed as:

$$
\sigma = \sqrt{\frac{\sum_{i=1}^k (n_i - 1)S_i^2}{\sum_{i=1}^k (n_i - 1)}}
$$

where $n_i$ is the sample size and $S_i$ the standard deviation of group $i$.

For a balanced design with equal group sizes $n$ , $\sigma$ is calculated as:

$$
\sigma = \sqrt{\frac{\sum_{i=1}^k S_i^2}{k}}
$$

Here we define a function named `cohens.f()` to compute Cohen’s f with the group means and the standard deviations:

```{r}
# Function to calculate Cohen's f for ANOVA
cohens.f <- function(means, sds) {
  grand_mean <- mean(means)
  pooled_sd <- sqrt(mean(sds^2))
  sd_mean <- sqrt(mean((means - grand_mean)^2))
  
  # Calculate Cohen's f
  cohens_f <- sd_mean / pooled_sd
  return(cohens_f)
}
```

::: example
A scientist plans to study the effects of Bifidobacterium and colchicine on liver fibrosis in mice. The mice will be randomly divided into three groups: a model (control) group, a Bifidobacterium infantis group, and a colchicine group. One primary outcome is the liver weight index in the mice. It is estimated that the liver weight index for each group at the end of the experiment will be 6.20, 5.40, and 4.70, respectively, with standard deviations of 1.87, 1.56, and 1.52. With a significance level of $\alpha = 0.05$ and power of $1 - \beta = 0.90$, how many mice are needed in each group to detect a significant difference?
:::

The `power.anova.test()` function and `pwr.anova.test()` function can perform this calculation for this example:

```{r}
means <- c(6.20, 5.40, 4.70)
sds <- c(1.87, 1.56, 1.52)

power.anova.test(
  groups = 3, between.var = var(means), within.var = mean(sds^2),
  sig.level = 0.05, power = 0.9) 
```

```{r}
f <- cohens.f(means, sds)

power.htest <- pwr.anova.test(k = 3, f = f, sig.level = 0.05, power = 0.9)
power.htest
power.htest |> plot()
```

For the given parameters, the output shows that each group should include 32 subjects. This sample size ensures a 90% chance of detecting a meaningful difference between the groups.

::: callout-tip
The `effectsize` package provides various effect size calculations, including Cohen’s f for ANOVA directly from model objects. If you have original data collected from a pilot study, first conduct an ANOVA and then extract the effect size.
:::

```{r}
set.seed(2024)

# Example data frame for ANOVA analysis
data <- data.frame(
  group = factor(c(rep("A", 15), rep("B", 15), rep("C", 15))),
  x = c(
    rnorm(15, 6.20, 1.87), rnorm(15, 5.40, 1.56), rnorm(15, 4.70, 1.52))
)

model <- aov(x ~ group, data = data)
cohens_f(model, partial = F, alternative = "two.sided")
```

### Comparison of proportions

**1. One-sample proportion**

When comparing a sample proportion to a known population proportion, the goal is typically to determine whether the observed sample proportion differs significantly from the known or expected proportion in the population.

For a large sample (typically $n \geq 30$, or more strictly when $np \geq 5$ and $n(1 - p) \geq 5$), a z-test is appropriate to compare the sample proportion to the known population proportion. This is because, with a large sample size, the distribution of the sample proportion approximates a normal distribution. The z-test statistic for this test is calculated as:

$$
z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}}
$$

where $\hat{p}$ is the sample proportion, $p_0$ is the known population proportion, $n$ is the sample size.

To estimate the sample size needed for this test with specified significance level and power, use the following formula:

$$
n = \frac{(Z_{1 - \alpha/2} + Z_{1 - \beta})^2 \cdot p_0 (1 - p_0)}{(\hat{p} - p_0)^2}
$$

where $Z_{1 - \alpha/2}$ is the Z-value for the significance level, $Z_{1 - \beta}$ is the Z-value associated with the desired power.

For small samples (when $n < 30$ , or $np < 5$ and $n(1 - p) < 5$), the z-test is not suitable because the sample proportion distribution does not approximate a normal distribution. Instead, a binomial test is recommended for small sample sizes. The binomial test is a non-parametric test, appropriate when normality cannot be assumed. It directly evaluates the difference in proportions based on the binomial distribution, providing a more accurate result for small samples.

::: example
A pharmaceutical institute has developed a new drug expected to increase the effective rate of treating lung cancer model mice from the conventional 45% to 60%. To conduct an animal experiment, how many lung cancer model mice are required to detect an improvement of 15% in the effective rate of the new drug?
:::

Here we write a function named `ss.one.prop()` to compute the sample size based on the formula above:

```{r}
ss.one.prop <- function(p0, p, alpha = 0.05, power = 0.9, alternative = "one.sided") {
  if (alternative == "one.sided") {
    z_alpha <- qnorm(1 - alpha)
  } else if (alternative == "two.sided") {
    z_alpha <- qnorm(1 - alpha / 2)
  } else {
    stop("alternative must be 'one.sided' or 'two.sided'")
  }
  z_beta <- qnorm(power)
  numerator <- (z_alpha + z_beta)^2 * p0 * (1 - p0)
  denominator <- (p - p0)^2
  n <- numerator / denominator
  
  METHOD <- "One-sample comparison of proportion sample size calculation"
  
  structure(
    list(n = n, alpha = alpha, power = power, alternative = alternative, 
         method = METHOD), 
    class = "power.htest")
}
```

```{r}
ss.one.prop(p0 = 0.45, p = 0.6, alpha = 0.05, power = 0.9)
```

Alternatively, you can use the `pwr.p.test()` function from the `pwr` packages:

```{r}
h <- ES.h(0.6, 0.45)

pwr.p.test(h = h, sig.level = 0.05, power = 0.9, alternative = "greater")
```

In summary, for a study designed to detect an effect size (h = 0.3015) with 90% power and a 5% significance level, you would need approximately 95 observations in a one-sided test to determine if the sample proportion is significantly greater than the population proportion.

**2. Two-sample proportions**

To compare two independent sample proportions, we generally conduct a hypothesis test for the difference between two population proportions. This is typically done using a two-sample z-test for proportions. The test statistic follows a normal distribution (under large sample sizes) and is calculated as:

$$
Z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}}
$$

where $\hat{p}_1$ and $\hat{p}_2$ are the two sample proportions, $n_1$ and $n_2$ are the sample sizes of each group, $\hat{p}$ is the pooled sample proportion, which is the weighted average of the two sample proportions:

$$
\hat{p} = \frac{x_1 + x_2}{n_1 + n_2}
$$

where $x_1$ and $x_2$ are the number of successes (events of interest) in each group.

To estimate the sample size required for detecting a difference between two independent sample proportions, the following formula can be used:

$$
n_1 = n_2 = \frac{\left( Z_{\alpha/2} + Z_{\beta} \right)^2} {2(\text {sin}^{-1} \sqrt{p_1} - \text {sin}^{-1} \sqrt{p_2})^2}
$$

where $Z_{\alpha/2}$ is the critical value for the two-sided test at significance level $\alpha$, $Z_{\beta}$ is the critical value corresponding to the desired power.

Here we write a function named `ss.two.prop()` to compute the sample size based on the formula above:

```{r}
ss.two_prop <- function(p1, p2, alpha = 0.05, power = 0.9, alternative = "two.sided") {
  # Calculate Z-scores for significance level based on test type
  if (alternative == "two.sided") {
    z_alpha <- qnorm(1 - alpha / 2)  # Two-sided test
  } else if (alternative == "one.sided") {
    z_alpha <- qnorm(1 - alpha)  # One-sided test
  } else {
    stop("alternative must be 'two.sided', 'one.sided'")
  }
  
  z_beta <- qnorm(power)
  numerator <- (z_alpha + z_beta)^2 
  denominator <- 2 * (asin(sqrt(p1)) - asin(sqrt(p2)))^2
  n <- numerator / denominator
  
  NOTE <-  "n is the sample size for each group"
  METHOD <- "Two-sample comparison of proportions sample size calculation"
  structure(
    list(
      n = n, alpha = alpha, power = power, alternative = alternative, 
      method = METHOD, note = NOTE), 
    class = "power.htest")
}
```

```{r}
ss.two_prop(p1 = 0.95, p2 = 0.80, alpha = 0.05, power = 0.9, alternative = "two.sided")
```

Alternatively, you can use the `power.prop.test()` function from the `stats` packages:

```{r}
power.prop.test(p1 = 0.95, p2 = 0.8, sig.level = 0.05,
  power = 0.9, alternative = "two") 
```

Another calculation method is the `pwr.2p.test()` function from the `pwr` packages:

```{r}
h <- ES.h(0.95, 0.8)

power.htest <- pwr.2p.test(h = h, sig.level = 0.05, power = 0.9, alternative = "two")
power.htest
power.htest |> plot()
```

It should be noticed that the sample sizes calculated by `power.prop.test()` and `pwr.2p.test()` are different. The difference comes from the underlying methodologies they use to estimate effect size and power. Here’s a brief explanation of each:

-   `power.prop.test()` uses a standard normal approximation for the difference between two proportions, calculating power based on a more traditional Z-test approach. It does not transform the proportions and operates directly on the difference in proportions (p1 - p2).
-   `pwr.2p.test()` from the `pwr` package uses Cohen’s h, which is based on the arcsine transformation of the proportions. Cohen’s h is a measure of effect size that is specifically adjusted for proportions, aiming to improve the estimation’s stability, especially when proportions are near 0 or 1.

If you are working with proportions that are close to 0 or 1, `pwr.2p.test()` may provide a more accurate sample size estimate due to Cohen’s h. If both proportions are more central, then either method could be appropriate, though results will vary due to these differences.

**3. Multiple sample proportions**

When comparing the proportions of multiple samples, we are typically interested in determining whether there are statistically significant differences among the groups. Chi-square test is used to determine if there is a significant association between categorical variables. It can be applied when you have one categorical variable from two or more independent samples. The formula for calculating sample size for each group in a multiple-proportion comparison is:

$$
n = \frac{\lambda} {2(\sin^{-1} \sqrt{p_{\text{max}}} - \sin^{-1} \sqrt{p_{\text{min}}})^2}
$$

where $p_{\text{max}}$is the highest proportion (efficacy rate) among the groups, $p_{\text{min}}$ is the lowest proportion among the groups, $\lambda$ is the non-centrality parametera, which is a constant that depends on the desired significance level and power.

::: example
To observe the effects of 3 methods for treating peptic ulcers in rats, it is preliminarily estimated that method A has an efficacy rate of 40%, method B has an efficacy rate of 50%, and method C has an efficacy rate of 65%. Assuming $α = 0.05$ and $β = 0.10$, to conclude that there are differences in efficacy rates, how many rats need to be observed in each group?
:::

For a given power $1 - \beta$, significance level $\alpha$, and effect size $w$, the sample size $N$ can be calculated using the `pwr.chisq.test()` function, which is based on the non-central chi-squared distribution. This approach ensures accurate power calculations, especially for cases where the central approximation does not hold.

```{r}
k <- 3
p0 = c(0.4, 0.5, 0.65);  p1 = c(0.6, 0.5, 0.35)
P = matrix(c(p0, p1), nrow = k) / k
w1 = ES.w2(P)                                         # <1>
w2 <- cohens_w(P, alternative = "two.sided") |> pluck(1)  # <1>

pwr.chisq.test(w = w1, df = 2, sig.level = 0.05, power = 0.9) 
pwr.chisq.test(w = w2, df = 2, sig.level = 0.05, power = 0.9)
```

1.  Calculate the effect size, with the same results

### Linear correlation

In linear correlation analysis, sample size estimation is typically done to achieve a specified power in hypothesis test. The sample size required depends on the expected effect size (correlation coefficient), significance level $\alpha$, and desired power $1 -\beta$. The sample size $N$ can be estimated using the following formula:

$$
N = \frac{(Z_{\alpha / 2} + Z_{\beta})^2}{\left(0.5 \times \ln\left(\frac{1 + r}{1 - r}\right)\right)^2} + 3
$$

where $r$ expected correlation coefficient (effect size), $Z_{\alpha / 2}$ is the critical value from the standard normal distribution for the significance level $\alpha$ (for a two-tailed test, use $\alpha / 2$), $Z_{\beta}$ is the critical value from the standard normal distribution for the power level $1 - \beta$, and $\ln\left(\frac{1 + r}{1 - r}\right)$represents Fisher’s z-transformation of the correlation coefficient $r$, which converts the correlation coefficient to a standard normal form.

The following function named `ss.linear.corr()` can be used to calculate the sample size needed for correlation analysis based on the above formula:

```{r}
ss.linear.corr <- function(sig.level = 0.05, power = NULL, r, alternative = "two.sided") {
  # Calculate z-scores
  if (alternative == "two.sided") {
    z_alpha <- qnorm(1 - sig.level / 2)  # Two-sided test
  } else if (alternative == "one.sided") {
    z_alpha <- qnorm(1 - alpha)  # One-sided test
  } else {
    stop("alternative must be 'two.sided', 'one.sided'")
  }
  z_beta <- qnorm(power)
  
  # Calculate Fisher's z transformation of r
  z_r <- 0.5 * log((1 + r) / (1 - r))
  
  # Calculate sample size
  n <- (z_alpha + z_beta)^2 / z_r^2 + 3
  
  METHOD <- "A approximate correlation sample size calculation"
  structure(
    list(
      n = n, r = r, sig.level = sig.level, power = power,
      method = METHOD), 
    class = "power.htest")
}
```

::: example
According to previous experience, the correlation coefficient between food intake and weight gain in rats is known to be 0.8. To obtain a statistically significant conclusion for this correlation at a significance level of $\alpha = 0.05$ and power level of $1 - \beta$ = 0.90, how many rats should be studied?
:::

```{r}
ss.linear.corr(sig.level = 0.05, power = 0.9, r = 0.8)
```

Alternative, you can use the `pwr.r.test()` function from the `pwr` packages:

```{r}
pwr.r.test(sig.level = 0.05, power = 0.9, r = 0.8) 
```

## Observational studies

In observational studies, the sample size required for estimating population parameters typically depends on the following factors:

**1. Confidence level (**$1 - \alpha$**)**

It is commonly set at 95% (corresponding to $\alpha = 0.05$), the confidence level determines the width of the confidence interval around the estimate. Higher confidence levels increase the required sample size.

**2. Margin of error (**$d$**)**

This is the allowable deviation between the estimate and the true population parameter, such as 5%. A smaller margin of error requires a larger sample size.

**3. Estimated proportion or effect size (**$p$ **or** $\theta$**)**

For proportion estimates, an estimated proportion $p$ from prior studies (e.g., 20% disease prevalence) is often used. For mean estimates, an anticipated standard deviation or measure of variability is needed.

4\. **Standard deviation (**$\sigma$**)**

For continuous variables, an anticipated population standard deviation $\sigma$ is needed to account for variability. Higher variability increases the sample size requirement.

**5. Power (**$1 - \beta$**)**

Power is the probability of detecting a true effect and is commonly set at 80% (corresponding to $\beta = 0.20$). Higher power requires a larger sample size.

**6. Design effect**

For studies using complex sampling designs (e.g., stratified or clustered sampling), a design effect is applied to account for the potential increase in required sample size due to the design.

**7. Number of strata or groups**

If the study involves stratified or subgroup analysis, the sample size in each stratum or group must be adequate to ensure reliable estimates within each subgroup.

These parameters collectively help determine the appropriate sample size for cross-sectional, case-control, or cohort studies, often using statistical formulas or software specifically designed for sample size estimation.

### Cross-sectional study

Cross-sectional studies typically aim to estimate the prevalence or proportion of an outcome (such as a disease or behavior) in a population.

**1. Simple random sampling**

In simple random sampling, the required sample size to estimate a population parameter accurately depends on the following formula and factors:

**For estimating a proportion**, the sample size $n$ can be calculated using:

$$
n = \frac{Z_{1-\alpha/2}^2 \cdot p \cdot (1 - p)}{d^2}
$$

where $Z_{1-\alpha/2}$ is the Z-score corresponding to the significance level, $p$ is the expected proportion or prevalence of the outcome (based on prior studies or estimates), $d$ is the desired margin of error.

```{r}
ss.srs.prop <- function(p, d, alpha) {
  z <- qnorm(1 - alpha / 2)
  n <- (z^2 * p * (1 - p)) / d^2
  n <- ceiling(n)
  
  METHOD <- "Sample size calculation for estimating a proportion"
  structure(
    list(
      n = n, alpha = alpha, p = p, d = d, method = METHOD), 
    class = "power.htest")
}
```

**For estimating a mean**, the sample size $n$ is:

$$
n = \frac{{Z_{1-\alpha/2}^2 \cdot \sigma^2}}{{d^2}}
$$

where $Z_{1-\alpha/2}$ is the Z-score corresponding to the significance level, $\sigma$ is the estimated population standard deviation, $d$ is the margin of error.

```{r}
ss.srs.mean <- function(sigma, d, alpha = 0.05) {
  z <- qnorm(1 - alpha / 2)
  n <- (z^2 * sigma^2) / d^2
  n <- ceiling(n)
  
  METHOD <- "Sample size calculation for estimating a mean"
  structure(
    list(
      n = n, alpha = alpha, sigma = sigma, d = d, method = METHOD), 
    class = "power.htest")
}
```

If the population size $N$ is finite and relatively small, the sample size can be adjusted using the finite population correction:

$$
n_{\text{adj}} = \frac{n}{1 + \frac{n - 1}{N}}
$$

where $n$ is the calculated sample size from the above formulas without the correction.

```{r}
adjusted.sample.size <- function(x, N) {
  n <- x$n
  n_adj <- n / (1 + (n - 1) / N)
  n_adj <- ceiling(n_adj)
  
  METHOD <- "Sample size adjusted by the finite population correction"
  structure(
    list(
      N= N, n = n, n_adj = n_adj, alpha = alpha, sigma = sigma,
      d = d, method = METHOD), 
    class = "power.htest")
}
```

::: example
To determine the prevalence of hypertension in a city’s population, given that the national prevalence of hypertension is 19.6% according to past data, and allowing for a margin of error of 0.01 with a significance level of $\alpha$ = 0.05, estimate the required sample size using simple random sampling.
:::

```{r}
p <- 0.196; d <- 0.01; alpha <- 0.05
ss.srs.prop(p, d, alpha)
```

::: example
A factory has 5,500 workers, and a simple random sample is planned to assess the average white blood cell count of the workers to determine whether working conditions affect white blood cell levels. The allowable error margin is set to 0.1 × 10⁹/L, and with a significance level of $\alpha$ = 0.05, how many workers need to be surveyed at minimum? (Based on previous data, the standard deviation of employees’ white blood cell counts is 0.95 × 10⁹/L)
:::

```{r}
alpha <- 0.05; sigma <- 0.95 * 10^9; d <- 0.1 * 10^9  
res <- ss.srs.mean(sigma, d, alpha)
adjusted.sample.size(res, N = 5500)
```

**2. Stratified random sampling**

In stratified random sampling, the formulas for calculating the total sample size needed to estimate a proportion and a mean are slightly different. Each involves breaking down the population into strata and using information within each stratum to improve the precision of the overall estimate.

**To estimate a proportion** with stratified random sampling, the sample size $n$ can be estimated using the following formula, which takes into account finite population correction and the weights of each strata.

$$
n = \frac{Z_{1-\alpha/2}^2 \sum_{h=1}^L W_h^2 \frac{\sqrt{p_h (1 - p_h)} \sum N_h \sqrt{p_h (1 - p_h)}}{N_h}}{d^2 + Z_{1-\alpha/2}^2  \frac{\sum_{h=1}^L W_h p_h (1 - p_h)}{N}}
$$

where $n$ is the total sample size across all strata, $Z_{1-\alpha/2}$ is the z-score corresponding to the desired confidence level, $W_h = N_h / N$ is the weight for the $h$-th stratum, representing the proportion of the stratum within the total population, $N_h$ is the population size of the $h$-th stratum, $N$ is the overall population size, $p_h$ is the estimated proportion in the $h$-th stratum, $d$ is the allowable margin of error, and $L$ total number of strata.

Once $n$ is calculated, the sample size for each stratum $n_h$ can be determined using Neyman (optimal) allocation:

$$
n_h = n \times \frac{N_h \sqrt{p_h (1 - p_h)}}{\sum_{h=1}^L N_h \sqrt{p_h (1 - p_h)}}
$$

This allocation minimizes the variance in estimating the overall proportion.

```{r}
ss.strata.prop <- function(N_h, p_h, d, alpha = 0.05) {
  N <- sum(N_h)
  z <- qnorm(1 - alpha / 2)
  W_h <- N_h / N 
  u <- sum(N_h * sqrt(p_h * (1 - p_h)))
  numerator <- z^2 * sum(W_h^2 * sqrt(p_h * (1 - p_h)) * u / N_h)
  denominator <- d^2 + z^2 * sum(W_h * p_h * (1 - p_h) / N)
  
  n <- numerator / denominator
  n_h <- (n * N_h / N) * (N_h - n / N) / (N_h -1)
  n <- ceiling(n)
  n_h <- ceiling(n_h)
  
  METHOD <- "Sample size calculation for estimating a proportion"
  structure(
    list(n = n, n_h = n_h, alpha = alpha, d = d, method = METHOD), 
    class = "power.htest")
}
```

**When estimating a mean**, the total sample size $n$ for stratified sampling, adjusted for finite population correction, can be estimated using:

$$
n = \frac{Z_{1- \alpha/2}^2 \sum_{h=1}^L W_h^2 \frac{S_h \sum N_h S_h}{N_h}}{d^2 + Z_{1- \alpha/2} ^2\sum_{h=1}^L \frac{W_h S_h^2}{N}}
$$

where $S_h$ is the standard deviation within the $h$-th stratum (an estimate of the population variance within each stratum). Other terms are as defined above.

Similar to proportions, Neyman allocation for means is:

$$
n_h = n \times \frac{N_h S_h}{\sum_{h=1}^L N_h S_h}
$$

where $S_h$ is the standard deviation within each stratum. This allocation ensures efficient estimation by reducing sampling error.

```{r}
ss.strata.mean <- function(N_h, S_h, d, alpha = 0.05) {
  N <- sum(N_h)
  z <- qnorm(1 - alpha / 2)
  
  u <- z^2 * sum((N_h / N)^2 * (S_h * sum(N_h * S_h)) / N_h)
  v <- d^2
  w <- z^2 * sum((N_h / N) * S_h^2 / N) 
  
  # Calculate sample size
  n <- u / (v + w)
  n_h <- n * (N_h * S_h) / sum(N_h * S_h)
  
  n <- ceiling(n)
  n_h <- ceiling(n_h)
  
  METHOD <- "Sample size calculation for estimating a mean"
  structure(
    list(n = n, n_h = n_h, alpha = alpha, d = d, method = METHOD), 
    class = "power.htest")
}
```

::: example
To conduct a stratified random sampling survey on the annual medical expenses of workers in a certain factory, past survey data is provided in @tbl-drug-expense . The goal is to understand the annual medical expenses of the factory’s employees, with an allowable margin of error, $\delta$, not exceeding 5 yuan and with a confidence level of $\alpha = 0.05$. What is the minimum number of workers that need to be surveyed?
:::

```{r}
#| echo: false
#| label: tbl-drug-expense
#| tbl-cap: Drug expenses of workers in each workshop of a factory
tibble(
  workshop = c(1:3),
  n = c(1200, 3200, 600),
  mean = c(180, 150, 260),
  sd = c(65, 50, 90)
) |> 
  knitr::kable(align = "c")
```

```{r}
N_h <- c(1200, 3200, 600)  # Population size for each stratum
S_h <- c(65, 50, 90) # Standard deviation for each stratum
d <- 5                     # Allowable error
alpha <- 0.05

ss.strata.mean(N_h, S_h, d, alpha = 0.05)
```

**3. Cluster sampling**

Cluster sampling is a sampling method where the population is divided into separate groups, called clusters, and a random sample of these clusters is selected for study. Cluster sampling is often used when the population is large and geographically dispersed, as it can be more practical and cost-effective than simple random sampling.

**Estimating sample size for population proportion**

For an infinite population, the required sample size for estimating a population proportion is calculated using:

$$
k = Z_{1-\alpha/2}^2 \sum \frac{m_h^2 (p_h - p)^2}{(k_y - 1) \bar m^2 d^2}
$$

For a finite population, adjust the sample size as follows:

$$
k_\text {adj} = k \left(1 - \frac{k_0}{K}\right)
$$ {#eq-adj-k0}

where $Z_{1 - \alpha / 2}$ is the Z-score corresponding to the desired confidence level, $k_0$ is the sample size for an infinite population, $k$ is the number of clusters to be surveyed, $m_h$ is the number of individuals surveyed in the $h$-th cluster, $p_h$ is the event occurrence rate in the $h$-th cluster, $\bar m$ is the average number of individuals per cluster, $p$ is the average occurrence rate, $d$ is the allowable error margin, and $K$ is the total number of clusters in the population.

```{r}
ss.cluster.prop <- function(m_h, p_h, K, d, alpha = 0.05) {
  z <- qnorm(1 - alpha / 2)
  k_y <- length(m_h)
  m <- sum(m_h) / k_y
  p <- sum(m_h * p_h) / sum(m_h)
  sum_p <- sum(m_h^2 * (p_h - p)^2 / ((k_y - 1) * m^2 * d^2))
  k <- z^2 * sum_p
  k.adj <- k * (1 - k / K)
  
  k <- ceiling(k)
  k.adj <- ceiling(k.adj)
  
  METHOD <- "Sample size calculation for estimating a proportion"
  structure(
    list(k = k, k.adj = k.adj, alpha = alpha, d = d, method = METHOD),
    class = "power.htest")
}
```

**Estimating sample size for population mean**

For an infinite population, the required sample size for estimating a population mean is calculated using:

$$
k_0 = Z_{\alpha/2}^2 \sum \frac{m_h (\bar{X}_h - \bar{X})^2}{(k_y - 1) \bar m^2 d^2}
$$

where $\bar{X}_i$ is the mean of the observed index for the $i$-th cluster, $\bar{X}$ is the overall mean. Other variables have meanings similar to those in the proportion estimation formula.

For a finite population, adjust the sample size as @eq-adj-k0 .

```{r}
ss.cluster.mean <- function(m_h, x_h, K, d, alpha = 0.05) {
  z <- qnorm(1 - alpha / 2)
  k_y <- length(m_h)
  m <- sum(m_h) / k_y
  x <- sum(m_h * x_h) / sum(m_h)
  sum_m <- sum(m_h^2 * (p_h - p)^2 / ((k_y - 1) * m^2 * d^2))
  k <- z^2 * sum_m
  k.adj <- k * (1 - k / K)
  
  k <- ceiling(k)
  k.adj <- ceiling(k.adj)
  
  METHOD <- "Sample size calculation for estimating a mean"
  structure(
    list(k = k, k.adj = k.adj, alpha = alpha, d = d, method = METHOD),
    class = "power.htest")
}
```

::: example
To estimate the prevalence of cardiovascular and cerebrovascular diseases in people over 40 in a city, a cluster sampling survey is planned across 62 communities. A preliminary survey was conducted in two districts, randomly selected by the survey team: In the first district, 5,368 people were surveyed, with 1,860 cases of cardiovascular and cerebrovascular diseases, resulting in a prevalence rate of 0.3465. In the second district, 6,236 people were surveyed, with 1,268 cases, resulting in a prevalence rate of 0.2033. The question is: How many districts need to be surveyed to estimate the prevalence, given a significance level of $\alpha = 0.05$ and a margin of error $\delta = 0.1$?
:::

```{r}
m_h <- c(5368, 6236)
p_h <- c(0.3465, 0.2033)
K <- 62
d <- 0.1
alpha <- 0.05
ss.cluster.prop(m_h, p_h, K, d, alpha)
```

### **Case-control study**

Sample size estimation for a case-control study is essential to ensure adequate power to detect an association between exposure and outcome. The required sample size can be estimated based on the expected odds ratio for the exposure between cases and controls, the prevalence of exposure in the control group, desired significance level, power, and ratio of controls to cases. This ratio is often set to 1 (equal number of cases and controls), but can be different.

For a case-control study, the sample size $n_1$ (cases) and $n_0$ (controls) can be estimated using the following formula:

$$
n1 = \frac{\left(Z_{1-\alpha/2} \sqrt{2p(1 - p)} + Z_{1-\beta} \sqrt{p_1(1 - p_1) + p_0(1 - p_0)}\right)^2}{(p_1 - p_0)^2}
$$

where $Z_{1-\alpha/2}$ and $Z_{1-\beta}$ are the Z-scores for the significance level $\alpha$ and desired power $1 - \beta$, respectively, $p_0$ is the the proportion of controls expected to have the exposure, $p_1$ is the expected proportion of exposure in cases, which can be calculated using the odds ratio (OR):

$$
p_1 = \frac{\text {OR} \times p_0}{1 + p_0 \times (\text {OR} - 1)}
$$

$p = \frac{p_1 + p_0}{2}$ is the average of exposure rates in cases and controls. The sample size of control $n_0 = k \times n_1$, where $k$ is the ratio of controls to cases. The total sample size is then obtained by $n = n_0 + n_1$,

```{r}
ss.case.control <- function(p0, or, alpha, beta, k = 1){
  z_alpha <- qnorm(1 - alpha / 2)
  z_beta <- qnorm(1 - beta)
  p1 <- (or * p0) / (1 + p0 * (or - 1))
  p <- (p0 + p1) / 2
  
  u <- (z_alpha * sqrt(2 * p * (1 - p)) + 
        z_beta * sqrt(p1 * (1 - p1) + p0 * (1 - p0)))^2
  v <- (p1 - p0)^2
  n1 <- ceiling(u / v)
  n0 <- ceiling(k * n1)

  METHOD <- "Sample size calculation for case-control study"
  structure(
    list(n0 = n0, n1 = n1, alpha = alpha, beta = beta, 
         OR = or, method = METHOD),
    class = "power.htest")
}
```

```{r}
p0 <- 0.3; or <- 3; alpha <- 0.05; beta <- 0.1
ss.case.control(p0, or, alpha, beta)
```

### Cohort study

In cohort studies, sample size estimation typically depends on the incidence rates in the exposed and unexposed groups and the expected risk ratio (RR). The formula is similar to that used in case-control studies:

$$
n1 = \frac{\left(Z_{1-\alpha/2} \sqrt{2p(1 - p)} + Z_{1-\beta} \sqrt{p_1(1 - p_1) + p_0(1 - p_0)}\right)^2}{(p_1 - p_0)^2}
$$

where $p_1$ and $p_0$ represent the expected incidence rates for the exposed and unexposed groups, respectively, $p_1$ can be calculated by RR: $p_1 = p_0 \times \text {RR}$.

```{r}
ss.cohort <- function(p0, rr, alpha, beta, k = 1){
  z_alpha <- qnorm(1 - alpha / 2)
  z_beta <- qnorm(1 - beta)
  p1 <- rr * p0
  p <- (p0 + p1) / 2
  
  u <- (z_alpha * sqrt(2 * p * (1 - p)) + 
        z_beta * sqrt(p1 * (1 - p1) + p0 * (1 - p0)))^2
  v <- (p1 - p0)^2
  n1 <- ceiling(u / v)
  n0 <- ceiling(k * n1)

  METHOD <- "Sample size calculation for cohort study"
  structure(
    list(n0 = n0, n1 = n1, alpha = alpha, beta = beta, 
         RR = rr, method = METHOD),
    class = "power.htest")
}
```

```{r}
p0 <- 0.01; rr <- 2; alpha <- 0.05; beta <- 0.1
ss.cohort(p0, rr, alpha, beta)
```

## Survival analysis

### Two survival rates

The sample size for comparing two survival rates, assuming exponential survival times and using the log-rank test. This approach typically involves estimating the number of events required for sufficient statistical power in survival analysis.

The `getSampleSizeSurvival()` function from `rpact` packages can be used for this purpose:

::: example
A scientist plans to conduct a study comparing the effects of a new surgical method with a traditional surgical method on the survival outcomes of patients with malignant adrenal tumors. The recruitment period for the study is set for 1 year, with all subjects entering the study uniformly, and a follow-up period of 2 years. It is known that the 2-year survival rate for the traditional surgical method is 50%, and the anticipated 2-year survival rate for the new surgical method is 80%. The estimated loss to follow-up rate for both groups is 6% per year, with a contamination rate of 3% in each group. Assuming a two-sided significance level of $\alpha = 0.05$ and a power of $1 - \beta = 0.90$, what sample size is needed for this study?
:::

```{r}
res <- getSampleSizeSurvival(
  alpha = 0.05, sided = 2, beta = 0.1, twoSidedPower = F, 
  pi1 = 0.5, pi2 = 0.8, eventTime = 24, followUpTime = 24, 
  accrualTime = c(0, 12), dropoutRate1 = 0.06, dropoutRate2 = 0.06, 
  typeOfComputation = "Freedman", allocationRatioPlanned = 1)

res |> 
  as_tibble() |> 
  select(pi1, pi2, hazardRatio, nFixed1, nFixed2)
```
