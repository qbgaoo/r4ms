# t-test

```{r}
#| echo: false

source("_common.R")
```

A t-test is a statistical test used to compare the means of two groups to determine if they are significantly different from each other. It is commonly used in situations where the sample size is small and the population variance is unknown. There are different types of t-tests depending on the study design and the nature of the data.

## Prerequisites

```{r}
#| message: false

library(tidyverse)
```

## One-sample t-test

The one-sample *t*-test is used to determine whether the mean of a single sample is significantly different from a known or hypothesized population mean. It is commonly used when you have a sample and want to test if its mean differs from a theoretical value or an expected value. Its test statistic t is calculated as follows:

$$
t = \frac{\bar{X} - \mu_0}{S_{\bar{X}}} = \frac{\bar{X} - \mu_0}{S / \sqrt{n}}
$$

where $\bar{X}$ si the sample mean , $S$ is the sample standard deviation and $n$ is the sample size, $\mu_0$ is the hypothesized population mean.

The one-sample *t*-test is a straightforward but powerful tool for hypothesis testing in many research scenarios.

::: example
A doctor measured the hemoglobin concentration in 36 male workers involved in lead-related jobs. The data can be downloaded below. The question is whether the mean hemoglobin concentration ($\mu$) of male workers involved in lead-related jobs differs from the mean of 140 (g/L) for normal adult males.
:::

<a href="datasets/ex07-01.csv" download="ex07-01.csv" class="btn btn-success"> <i class="bi bi-database-fill-down"></i> Download data </a>

R codes for one-sample *t*-test is:

```{r}
read_csv("datasets/ex07-01.csv", show_col_types = F) |> 
  t.test(mu = 140) 
```

The results show $t = -2.1367$ , $\text{p-value} = 0.03969$. At the significance level of $\alpha = 0.05$ , reject $H_0$ and accept $H_1$, indicating that the difference is statistically significant. In the context of this case, it can be concluded that the average hemoglobin concentration of male workers engaged in lead work is lower than the average hemoglobin concentration of normal adult males.

## Paired t-test

The paired *t*-test is used to compare the means of two related groups. This test is typically used when the observations are paired in some meaningful way, such as measurements taken on the same subjects at two different times or under two different conditions.

-   $H_0$ : The mean difference between the paired observations is zero ($\mu_d = 0$).
-   $H_1$ : The mean difference between the paired observations is not zero ($\mu_d \neq 0$).

The test statistic for the paired t-test is calculated as:

$$t = \frac{\bar{d}}{S_d / \sqrt{n}}$$ Where $\bar{d}$ is the mean of the differences between the paired observations, $S_d$ is the standard deviation of the differences, and $n$ is the number of pairs.

::: example
To compare whether the results of fat content measurement in lactic acid beverages differ between two methods, 10 samples of lactic acid beverages were randomly selected. The fat content was measured using both the Gerber-Gottlieb method and the fatty acid hydrolysis method. The data can be downloaded below. The question is whether the measurement results from the two methods are different?
:::

<a href="datasets/ex07-02.csv" download="ex07-02.csv" class="btn btn-success"> <i class="bi bi-database-fill-down"></i> Download data </a>

R codes for paired *t*-test is:

```{r}
read_csv("datasets/ex07-02.csv", show_col_types = F) |> 
  with(t.test(x1, x2, paired = T))
```

The results show $t = -2.1367$ , $\text{p-value} < 0.001$. At the significance level of $\alpha = 0.05$, reject $H_0$ and accept $H_1$, indicating that the difference is statistically significant. It can be concluded that the two methods yield different fat content measurements. As mean difference estimation is $0.2724 > 0$, the Gerber-Gottlieb method providing higher results.

## Two-sample t-test

The two-sample *t*-test (also known as the independent *t*-test) is used to determine whether there is a significant difference between the means of two independent groups. It is commonly used in experiments or studies where researchers want to compare the means of two different populations or conditions.

In medical study it is commonly used to compare the means of two samples in a completely randomized design. In this design, subjects are randomly assigned to two different treatment groups, and the researcher is interested in whether the means of these two samples represent different population means. Additionally, in observational studies, the two-sample *t*-test can be used to compare the means of two samples obtained through independent random sampling from two different populations.

When both samples come from normal populations, and the sample sizes are relatively small, such as $n_1 \leq 60$ or/and $n_2 \leq 60$ , different testing methods should be used depending on whether the population variances are equal.

### The t-test for equal population variances

The *t*-test for equal population variances, often referred to as the pooled variance *t*-test, is used when comparing the means of two independent samples under the assumption that the two populations have the same variance. This assumption allows the variances of the two samples to be combined (or pooled) into a single estimate, which can then be used in the *t*-test formula.

Before conducting the combined *t*-test, it’s common to perform an F-test to check if the variances of the two samples are equal. If the p-value from the F-test is not significant, the pooled *t*-test can be justified. The pooled variance is calculated as a weighted average of the variances from the two samples:

$$
S_c^2 = \frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}
$$

Here, $S_c^2$ is the combined variance, $S_1^2$ and $S_2^2$ are the variances of the two samples, and $n_1$ and $n_2$ are the sample sizes.

Once the combined variance is calculated, the *t*-statistic for the two-sample *t*-test can be computed as:

$$
t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{S_c^2 \left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}
$$

$\bar{X}_1$ and $\bar{X}_2$ are the sample means, and $n_1$ and $n_2$ are the sample sizes. The degrees of freedom for the pooled variance t-test are calculated as $n_1 + n_2 - 2$. 5.

$H_0$: There is no difference between the population means ($\mu_1 = \mu_2$).

$H_1$: There is a difference between the population means ($\mu_1 \neq \mu_2$).

If the variances are unequal, the Welch *t*-test (which does not assume equal variances) is recommended.

::: example
To investigate the anti-atherosclerotic effects of tetrandrine on rabbits, an atherosclerosis rabbit model was established using a high-fat diet over 12 weeks. 16 rabbits successfully modeled after 12 weeks were randomly divided into two groups. The model group was given a high-fat diet of 100g/day, while the tetrandrine group was given the same high-fat diet along with an additional 109mg/(kg·d) of tetrandrine mixed into the feed. After continuous feeding for 3 weeks, blood was drawn from the heart at the end of the experiment to measure the high-density lipoprotein (mmol/L) levels in the heart blood. The data can be downloaded below. Can it be concluded that the population means of high-density lipoprotein content in the heart blood differ between the model group and the tetrandrine group?
:::

<a href="datasets/ex07-03.csv" download="ex07-03.csv" class="btn btn-success"> <i class="bi bi-database-fill-down"></i> Download data </a>

R codes for two-sample *t*-test is:

```{r}
read_csv("datasets/ex07-03.csv", show_col_types = F) |> 
  t.test(x ~ grp, data = _, var.equal = T)                   # <1>
```

1.  Use the pipe operator to perform t-test with a group variable and a response variable.

The results show $t = 3.689$ , $\text{p-value} = 0.00243$. At the $\alpha = 0.05$ significance level, reject $H_0$ and accept $H_1$, indicating that the difference is statistically significant. It can be concluded that the population means of high-density lipoprotein content in the heart blood are different between the tetrandrine group and the model group. Considering the sample means in this case, it can be inferred that the population mean of high-density lipoprotein content in the heart blood is higher in the tetrandrine group than in the model group.

### Welch t-test for unequal population variances

Unlike the combined variance *t*-test, the Welch *t*-test does not assume that the two populations have the same variance. This is particularly useful when you suspect or know that the variances are different, or when the sample sizes are quite different, which makes it more flexible than the combined variance t-test.

The t-statistic for the Welch t-test is calculated as:

$$
t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}}}
$$

Here, $\bar{X}_1$ and $\bar{X}_2$ are the sample means, $S_1^2$ and $S_2^2$ are the variances of the two samples, and $n_1$ and $n_2$ are the sample sizes.

The degrees of freedom for the Welch *t*-test are calculated using the Welch-Satterthwaite equation:

$$
\nu = \frac{\left(\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}\right)^2}{\frac{\left(\frac{S_1^2}{n_1}\right)^2}{n_1 - 1} + \frac{\left(\frac{S_2^2}{n_2}\right)^2}{n_2 - 1}}
$$

This formula typically results in a non-integer value for the degrees of freedom, which is a characteristic of the Welch *t*-test. It is generally considered more robust than the combined variance *t*-test in situations where variances differ.

::: example
To analyze the effect of blood glucose control on serum total cholesterol levels, a study was conducted on type 2 diabetes patients in a community. Hemoglobin A1c (HbA1c) levels below 7.0% were used as the target for blood glucose control. Total cholesterol levels (mmol/L) were measured in 25 patients with poor blood glucose control (Group A) and 25 patients with good blood glucose control (Group B). The data can be downloaded below. Determine whether the mean total cholesterol levels of those with poor blood glucose control and those with good blood glucose control are equal or not.
:::

<a href="datasets/ex07-04.csv" download="ex07-04.csv" class="btn btn-success"> <i class="bi bi-database-fill-down"></i> Download data </a>

R codes for Welch *t*-test is:

```{r}
read_csv("datasets/ex07-04.csv", show_col_types = F) |> 
  t.test(x ~ grp, data = _, var.equal = F)    
```

The results show $t = -2.8322$ , $\text{p-value} = 0.007465$. At the $\alpha = 0.05$ significance level, reject $H_0$ and accept $H_1$, indicating that the difference is statistically significant. Therefore, we can conclude that the mean total cholesterol levels between those with poor and good blood glucose control are different.

## Normality test and F-test

When conducting a two-sample *t*-test, especially when comparing the means of two small samples, it is required that the corresponding populations follow a normal distribution and that the population variances are equal, known as homogeneity of variance. For paired *t*-tests, it is only necessary that the distribution of the differences between each pair of data points follows a normal distribution. Therefore, when performing a two-sample *t*-test with small samples, it is generally advisable to first conduct a homogeneity of variance test, particularly when there is a noticeable disparity between the sample variances. If the variances are homogeneous, a standard *t*-test is used; if not, an approximate *t*-test, such as Welch *t*-test, is applied. Additionally, it may be necessary to perform a normality test, though normality tests are more commonly used to establish medical reference ranges using normal distribution methods.

### Normality test

For more details about normality test you can see @sec-normality-test .

## F-test 

The F-test was traditionally used to determine whether the variances of two populations are equal. However, this test assumes that the data follow a normal distribution, which is often not the case, especially when variances are unequal. Because of this limitation, the Levene’s test has become more popular in recent years. Levene’s test is more robust and does not rely on the specific distribution of the population. Levene’s test can be used to test the homogeneity of variances for both two populations and multiple populations.cHere, only the F-test for comparing the variances of two samples is introduced.

$H_0$: The variances of the two populations are equal ($\sigma_1^2 = \sigma_2^2$).

$H_1$: The variances of the two populations are not equal ($\sigma_1^2 \neq \sigma_2^2$).

The F-statistic is calculated as the ratio of the two sample variances:

$$
F = \frac{S_1^2}{S_2^2}
$$

where $S_1^2$ and $S_2^2$ are the variances of the two samples. By convention, $S_1^2$ should be the larger variance, so the F-statistic is always greater than or equal to 1. The F-distribution depends on two parameters: the degrees of freedom for the numerator ($\nu_1 = n_1 - 1$) and the denominator ($\nu_2 = n_2 - 1$).

If the calculated F-statistic is is close to 1, the variances are similar. If it is much larger or smaller than 1, there may be a significant difference. If the p-value is less than the chosen significance level (e.g., 0.05), reject the null hypothesis, indicating that the variances are significantly different.

The F-test is sensitive to non-normality. If the data does not follow a normal distribution, the test may give misleading results. In such cases, non-parametric alternatives, such as the Levene’s test, may be more appropriate.
