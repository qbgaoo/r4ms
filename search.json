[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Medical Statistics",
    "section": "",
    "text": "Preface\nThis book is created by Quarto and R in RStudio IDE。Quarto is an open-source publishing system that integrates well with R, enabling users to create dynamic documents that combine text, code, and output (like tables and plots) in a single document. It supports R Markdown, allowing the execution of R code within documents and rendering outputs in various formats, such as HTML, PDF, and Word. Quarto is ideal for creating reproducible reports, presentations, and books, especially in academic and research settings where R is extensively used. You can also manage bibliographies, citations, and cross-references easily. Quarto is highly customizable, allowing users to create complex documents with ease, and is often used with GitHub Actions for continuous integration and automated publishing.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Prerequisites\nWe’ve made a few assumptions about what you already know to get the most out of this book. You should have some basic knowledge about medical statistics, and it’s helpful if you have some basic R programming experience already.\nYou need some things to run the code in this book: R, RStudio and some preinstalled R packages. Packages are the fundamental units of reproducible R code. They include reusable functions, documentation that describes how to use them, and sample data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 R\nTo download R, go to CRAN, the comprehensive R archive network, https://cloud.r-project.org. A new major version of R comes out once a year, and there are 2-3 minor releases each year. It’s a good idea to update regularly. Upgrading can be a bit of a hassle, especially for major versions that require you to re-install all your packages, but putting it off only makes it worse. We recommend R 4.4.1 or later for this book.\n\n\n1.1.2 RStudio\nRStudio is an integrated development environment, or IDE, for R programming, which you can download from https://posit.co/download/rstudio-desktop/. RStudio is updated a couple of times a year, and it will automatically let you know when a new version is out, so there’s no need to check back. It’s a good idea to upgrade regularly to take advantage of the latest and greatest features. For this book, make sure you have at least RStudio 2024.04.2.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#running-r-code",
    "href": "intro.html#running-r-code",
    "title": "1  Introduction",
    "section": "1.2 Running R code",
    "text": "1.2 Running R code\nThe previous section showed you several examples of running R code. The code in the book looks like this:\n\n1 + 2\n\n#&gt; [1] 3\n\n\nIf you run the same code in your local console, it will look like this:\n&gt; 1 + 2\n[1] 3\nThere are two main differences. In your console, you type after the &gt;, called the prompt; we don’t show the prompt in the book. In the book, the output is commented out with #&gt;; in your console, it appears directly after your code. These two differences mean that if you’re working with an electronic version of the book, you can easily copy code out of the book and paste it into the console.\nThroughout the book, we use a consistent set of conventions to refer to code:\n\nFunctions are displayed in a code font and followed by parentheses, like sum() or mean().\nOther R objects (such as data or function arguments) are in a code font, without parentheses, like flights or x.\nSometimes, to make it clear which package an object comes from, we’ll use the package name followed by two colons, like dplyr::mutate() or nycflights13::flights. This is also valid R code.\nTo improves readability, variable names and function names are named using snake case.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#colophon",
    "href": "intro.html#colophon",
    "title": "1  Introduction",
    "section": "1.3 Colophon",
    "text": "1.3 Colophon\nThe book is written by Quarto, an online version of it is available at https://qbgaoo.github.io/r4ms/. It will continue to evolve in between reprints of the physical book. The source of the book is available at https://qbgaoo.github.io/r4ms/.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html",
    "href": "quat-data-stat-desc.html",
    "title": "2  Statistical description of quantitative data",
    "section": "",
    "text": "2.1 Prerequisite\nSetting up the required R packages.\nlibrary(tidyverse)\nHere we use read_csv() function to import the data file into R.\nmax_hr &lt;- read_csv(\"datasets/ex02-01.csv\")\n\n#&gt; Rows: 143 Columns: 1\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (1): max_hr\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nThe first argument is the most important: the path to the file. You can think about the path as the address of the file. The code above will work if you have a ex02-01.csv file in the datasets folder of your project.\nWhen you run read_csv(), it prints out a message telling you the number of rows and columns of data, the delimiter that was used, and the column specifications (names of columns organized by the type of data the column contains). It also prints out some information about retrieving the full column specification and how to quiet this message.\nThe data file has only one column with name max_hr. Let’s check if there are some missing values present in it.\nmax_hr |&gt; \n  anyNA()\n\n#&gt; [1] FALSE\nThe output FALSE indicates no missing values is present.",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#prerequisite",
    "href": "quat-data-stat-desc.html#prerequisite",
    "title": "2  Statistical description of quantitative data",
    "section": "",
    "text": "Example 1: \nSome researchers used a random sampling method to examine the maximum heart rate of 143 normal adult women. The measuring results are saved in a .csv file. Please use the data to create a frequency distribution table.",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#visualization",
    "href": "quat-data-stat-desc.html#visualization",
    "title": "2  Statistical description of quantitative data",
    "section": "2.2 Visualization",
    "text": "2.2 Visualization\n\n2.2.1 Frequency table\nA frequency table mentioned here is a statistical tool that organizes data into intervals and lists the number of frequency in each interval. It helps summarize large dataset by showing how often each value or range of values occurs, making it easier to identify trends and the overall distribution of the data. This table is often used in conjunction with visual tools like histogram to enhance data interpretation.\nHere is the steps for creating a frequency table for continuous variables.\n\nComputing the minimum and maximum of the variable.\n\n\nmin_max_hr &lt;- max_hr |&gt; \n  min()\n\nmax_max_hr &lt;- max_hr |&gt; \n  max()\n\n\nDetermining the number of intervals. The number of intervals is typically between 10 and 15; here, we adopt 10. The seq() function is used to obtain upper and lower limits of the intervals.\n\n\nn_of_bins = 10\nbreaks &lt;- seq(min_max_hr, max_max_hr, length.out = n_of_bins + 1)\nbreaks\n\n#&gt;  [1]  90.0 100.2 110.4 120.6 130.8 141.0 151.2 161.4 171.6 181.8 192.0\n\n\n\nUsing the cut() function to dive each data into their respective intervals.\n\n\ncut(pull(max_hr), breaks = breaks, include.lowest = T, right = F) |&gt; \n  head(40)\n\n#&gt;  [1] [161,172) [110,121) [141,151) [131,141) [141,151) [161,172) [141,151)\n#&gt;  [8] [161,172) [121,131) [151,161) [141,151) [141,151) [121,131) [121,131)\n#&gt; [15] [141,151) [131,141) [161,172) [172,182) [141,151) [121,131) [141,151)\n#&gt; [22] [110,121) [141,151) [141,151) [151,161) [141,151) [172,182) [100,110)\n#&gt; [29] [121,131) [131,141) [182,192] [131,141) [182,192] [172,182) [131,141)\n#&gt; [36] [110,121) [172,182) [172,182) [131,141) [90,100) \n#&gt; 10 Levels: [90,100) [100,110) [110,121) [121,131) [131,141) ... [182,192]\n\n\n\nGenerating the frequency table.\n\n\ncut(pull(max_hr), breaks = breaks, include.lowest = T, right = F) |&gt;\n  table() |&gt; \n  knitr::kable(col.names = c(\"interval\", \"freq\"), align = \"c\")\n\n\n\n\ninterval\nfreq\n\n\n\n\n[90,100)\n4\n\n\n[100,110)\n2\n\n\n[110,121)\n12\n\n\n[121,131)\n17\n\n\n[131,141)\n13\n\n\n[141,151)\n22\n\n\n[151,161)\n26\n\n\n[161,172)\n24\n\n\n[172,182)\n18\n\n\n[182,192]\n5\n\n\n\n\n\n\n\n2.2.2 Frequency histogram\nA frequency histogram is a graphical representation of a frequency table. It displays the distribution of numerical variales by showing the frequency (count) of a value within specific intervals (bins) on the x-axis, with the y-axis representing the frequency. Each bar in the histogram corresponds to an interval, and the height of the bar indicates how many valuess fall within that range. This visual tool is useful for quickly assessing the shape, spread, and central tendency of the data distribution.\n\nhist(\n  x              = pull(max_hr), \n  breaks         = breaks, \n  freq           = T,\n  right          = F, \n  col            = \"skyblue\", \n  include.lowest = T,\n  main           = \" \",\n  xlab           = \"Maximum heart rate\",\n  ylab           = \"Frequency\",\n  ylim           = c(0, 30),\n  labels         = T\n)\n\n\n\n\n\n\n\n\nAn alternative approach to plot the same histogram is also supplied below.\n\nmax_hr |&gt; \n  ggplot(aes(x = max_hr)) +\n  geom_histogram(\n    fill = \"skyblue\", \n    stat = \"bin\",\n    color = \"black\",\n    breaks = breaks,\n    closed = \"left\"\n  ) +\n  stat_bin(\n    geom = \"text\", \n    aes(label = after_stat(count)),\n    breaks = breaks, \n    closed = \"left\",\n    size = 4,\n    vjust = - 0.3\n  ) +\n  labs(x = \"Maximum heart rate\", y = \"Frequency\") +\n  theme(\n    axis.title.x = element_text(size = 12), \n    axis.title.y = element_text(size = 12), \n    axis.text.x = element_text(size = 11),  \n    axis.text.y = element_text(size = 11),\n    panel.background = element_blank(),        \n    axis.line = element_line(color = \"black\") \n  )\n\n\n\n\n\n\n\n\n\nlibrary(shiny)\n\nshinyApp(\n  ui = fillPage(\n    \n    # App title ----\n    title = \"Frequency distribution graph\",\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"bins\",\n                        \"Number of bins:\",\n                        min = 10,\n                        max = 15,\n                        value = 10)\n        ),\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"distPlot\")\n        )\n    )\n),\n  server = function(input, output) {\n    input\n    output$distPlot &lt;- renderPlot({\n        # generate bins based on input$bins from ui.R\n        x    &lt;- faithful[, 2]\n        bins &lt;- seq(min(x), max(x), length.out = input$bins + 1)\n\n        # draw the histogram with the specified number of bins\n        hist(x, breaks = bins, col = 'skyblue', border = 'black',\n             xlab = 'Maximum heart rate',\n             main = '')\n    })\n}\n)\n\nShiny applications not supported in static R Markdown documents",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#measures-of-central-tendency",
    "href": "quat-data-stat-desc.html#measures-of-central-tendency",
    "title": "2  Statistical description of quantitative data",
    "section": "2.3 Measures of central tendency",
    "text": "2.3 Measures of central tendency\nCentral tendency is a statistical concept that refers to the measure of the center or typical value in a data set. It provides a summary of the data with a single value that represents the middle or average of the data. The most common measures of central tendency are:\n\n2.3.1 Mean\nThe arithmetic average of all values. It’s calculated by summing all the values and dividing by the number of values.\nFor a population:\n\\[\n\\mu = \\frac{\\sum X_i}{N}\n\\]\nFor a sample:\n\\[\n\\bar{X} = \\frac{\\sum X_i}{n}\n\\]\nwhere \\(X_i\\) represents each value, and \\(N\\) and \\(n\\) are the sizes of the population and sample, respectively.\n\nmax_hr |&gt; \n  pull() |&gt; \n  mean()\n\n#&gt; [1] 149.049\n\n\n\n\n2.3.2 Median\nThe middle value in a data set when the values are sorted in ascending order. If there is an even number of values, the median is the average of the two middle values. To find the median:\n\nSort the data set.\nIf the number of observations N is odd, the median is the middle value.\nIf N is even, the median is the average of the two central values.\n\n\nmax_hr |&gt; \n  pull() |&gt; \n  median()\n\n#&gt; [1] 152",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#measures-of-dispersion",
    "href": "quat-data-stat-desc.html#measures-of-dispersion",
    "title": "2  Statistical description of quantitative data",
    "section": "2.4 Measures of dispersion",
    "text": "2.4 Measures of dispersion\nDispersion or variability, describe the spread or dispersion of data points in a data set. They provide insight into how much individual data points differ from the central value (mean, median, etc.). Common measures of dispersion include:\n\n2.4.1 Range\nThe difference between the maximum and minimum values in the data set.\n\\[\n\\text{range} = \\text{max} - \\text{min}\n\\]\n\nrange(max_hr) |&gt; \n  diff()\n\n#&gt; [1] 102\n\n\n\n\n2.4.2 Interquartile Range (IQR)\nThe range of the middle 50% of the data, calculated as the difference between the 75th percentile (Q3) and the 25th percentile (Q1).\n\\[\n\\text{IQR} = Q3 - Q1\n\\]\nYou can directly use the IQR() function to get IQR.\n\nmax_hr |&gt; \n  pull() |&gt; \n  IQR()\n\n#&gt; [1] 32.5\n\n\n\n\n2.4.3 Variance\nMeasures the average squared deviation of each data point from the mean.\nFor a population:\n\\[\n\\sigma^2 = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\mu)^2\n\\]\nFor a sample:\n\\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2\n\\]\nwhere \\(\\mu\\) is the population mean, \\(\\bar{X}\\) is the sample mean, \\(X_i\\) represents each value, and \\(N\\) and \\(n\\) are are the sizes of the population and sample, respectively.\nYou can directly use the var() function to get variance.\n\nmax_hr |&gt; \n  pull() |&gt; \n  var()\n\n#&gt; [1] 466.4694\n\n\n\n\n2.4.4 Standard deviation\nThe square root of the variance, providing a measure of spread in the same units as the data.\nFor a population:\n\\[\n\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (X_i - \\mu)^2}\n\\]\nFor a sample:\n\\[\nS = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2}\n\\]\nYou can directly use the sd() function to get standard deviation.\n\nmax_hr |&gt; \n  pull() |&gt; \n  sd()\n\n#&gt; [1] 21.5979\n\n\n\n\n2.4.5 Coefficient of Variation (CV)\nThe ratio of the standard deviation to the mean, expressed as a percentage, useful for comparing variability between variables with different units or scales.\nFor a population:\n\\[\n\\text{CV} = \\frac{\\sigma}{\\mu} \\times 100%\n\\]\nwhere \\(\\sigma\\) is the standard deviation and \\(\\mu\\) is the mean of a population.\nFor a sample:\n\\[\n\\text{CV} = \\frac{S}{\\bar{X}} \\times 100%\n\\]\nwhere \\(S\\) is the standard deviation and \\(\\bar{X}\\) is the mean of a sample.\n\nmean &lt;- max_hr |&gt; \n  pull() |&gt; \n  mean()\n\nsd &lt;- max_hr |&gt; \n  pull() |&gt; \n  sd()\n\nsd / mean * 100\n\n#&gt; [1] 14.49048",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#medical-reference-range",
    "href": "quat-data-stat-desc.html#medical-reference-range",
    "title": "2  Statistical description of quantitative data",
    "section": "2.5 Medical reference range",
    "text": "2.5 Medical reference range\nA medical reference range is a set of values that is used by healthcare providers to interpret laboratory test results. These ranges are typically established by testing a large group of healthy individuals and determining the normal distribution of values within that population. The reference range provides a context for understanding whether a individual’s test results fall within a normal, expected range or if they indicate a potential health issue.\n\nmed_ref_range &lt;- max_hr |&gt; \n  pull() |&gt; \n  quantile(probs = c(0.025, 0.975)) |&gt; \n  round(digits = 0) |&gt; \n  print()\n\n#&gt;  2.5% 97.5% \n#&gt;   105   183\n\n\nThe result indicates that the 95% medical reference range for the maximum heart rate in normal individuals is: (105, 183)",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "ttest.html",
    "href": "ttest.html",
    "title": "5  Population mean estimation and t test",
    "section": "",
    "text": "5.1 Prerequisites\nlibrary(tidyverse)\nlibrary(kableExtra)",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Population mean estimation and *t* test</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-distribution",
    "href": "ttest.html#t-distribution",
    "title": "5  Population mean estimation and t test",
    "section": "5.2 t distribution",
    "text": "5.2 t distribution\n例3-1 若某市1999年18岁男生身高服从均数为167.7cm，标准差为5.3cm的正态分布。从该正态分布N(167.7, 5.32)cm总体中随机抽样100次即共抽取样本g=100个，每次样本含量10人，计算得到每个样本的均数及标准差，数据以Stata格式保存，利用haven::read_csv()函数导入R变量 height_sample 中。是部分数据。\n\nheight_sample &lt;- read_csv(\"datasets/ex03-01.csv\") \n\n#&gt; Rows: 100 Columns: 3\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (3): no, mean, sd\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(height_sample) |&gt; \n  kbl(align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n\n\nno\nmean\nsd\n\n\n\n\n1\n167.41\n2.74\n\n\n2\n165.56\n6.57\n\n\n3\n168.20\n5.36\n\n\n4\n166.67\n4.81\n\n\n5\n164.89\n5.41\n\n\n6\n166.36\n4.50",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Population mean estimation and *t* test</span>"
    ]
  },
  {
    "objectID": "ttest.html#标准误和可信区间",
    "href": "ttest.html#标准误和可信区间",
    "title": "5  Population mean estimation and t test",
    "section": "5.3 标准误和可信区间",
    "text": "5.3 标准误和可信区间\n\n5.3.1 单一总体均数的可信区间\n例3-2 计算例3-1中每个样本的标准误和可信区间\n\nmean  &lt;- height_sample$mean\nsd    &lt;- height_sample$sd\nlower_bound = vector(mode = \"double\", length = 100)\nupper_bound = vector(mode = \"double\", length = 100)\n\nfor(i in seq(1:100)){\n1  ttest &lt;- DescTools::TTestA(\n  mx = mean[i],\n  sx = sd[i],\n  nx = 10,\n  alternative = \"two.sided\",\n  mu = 167.7\n  )\n  ci &lt;- ttest$conf.int\n  lower_bound[i] &lt;- ci[1]\n  upper_bound[i] &lt;- ci[2]\n}\n\nheight_sample |&gt; \n  mutate(\n    se          = sd / sqrt(10),\n    lower_bound = lower_bound,\n    upper_bound = upper_bound\n  ) |&gt; \n  head()|&gt; \n  kbl(digits = 2, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\nTTestA()根据用户提供的统计量进行单个或两个样本 t 检验，而不是像t.test()中那样基于数据直接进行检验；此例是单样本，两样本类同，参见下例。\n\n\n\n\n\n\n\nno\nmean\nsd\nse\nlower_bound\nupper_bound\n\n\n\n\n1\n167.41\n2.74\n0.87\n165.45\n169.37\n\n\n2\n165.56\n6.57\n2.08\n160.86\n170.26\n\n\n3\n168.20\n5.36\n1.69\n164.37\n172.03\n\n\n4\n166.67\n4.81\n1.52\n163.23\n170.11\n\n\n5\n164.89\n5.41\n1.71\n161.02\n168.76\n\n\n6\n166.36\n4.50\n1.42\n163.14\n169.58\n\n\n\n\n\n\n\n\n\n5.3.2 两总体均数差的可信区间\n例3-3 61名患者随机分为两组，已知安慰剂组29例，试验组32例，治疗前安慰剂组IL-2的均数为20.1，标准差为7.02；试验组IL-2的均数为16.89，标准差为8.46。问两组治疗前基线的IL-2相差有多大？\n\nttest &lt;- DescTools::TTestA(\nmx = 20.1,\nmy = 16.89,\nsx = 7.02,\nsy = 8.46,\nnx = 29,\nny = 32,\nalternative = \"two.sided\"\n)\nci &lt;- ttest$conf.int |&gt; \n  round(digits = 2)\n\n因此，两组治疗前基线的IL-2总体均数之差的95%可信区间为(-0.76, 7.18)。",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Population mean estimation and *t* test</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-检验",
    "href": "ttest.html#t-检验",
    "title": "5  Population mean estimation and t test",
    "section": "5.4 t 检验",
    "text": "5.4 t 检验\n计量资料的假设检验中，最常见、最简单的方法是 t 检验。\n\n5.4.1 单样本 t 检验\n例3-4 某医生测量了36名从事铅作业男性工人的血红蛋白含量，算得其均数为130.83g/L，标准差为25.74g/L。问从事铅作业工人的血红蛋白是否不同于正常成年男性平均值140g/L？\n\nread_csv(\"datasets/ex03-05.csv\", show_col_types = F) |&gt; \n  t.test(mu = 140) |&gt; \n1  broom::tidy() |&gt;\n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F)\n\n\n1\n\n把一个对象变成一个整齐的tibble，方便表的格式化输出\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n130.833\n-2.137\n0.04\n35\n122.124\n139.543\nOne Sample t-test\ntwo.sided\n\n\n\n\n\n\n\n\n\n5.4.2 Paired sample t test\n例3-5 为比较两种方法对乳酸饮料中脂肪含量测定结果是否不同，随机抽取了10份乳酸饮料制品，分别用脂肪酸水解法和哥特里－罗紫法测定其结果。问两法测定结果是否不同？\n\npaired &lt;- read_csv(\"datasets/ex03-06.csv\") \n\n#&gt; Rows: 10 Columns: 3\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (3): no, x1, x2\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nt.test(\n  x = paired$x1,\n  y = paired$x2,\n  paired = T\n) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.272\n7.926\n0\n9\n0.195\n0.35\nPaired t-test\ntwo.sided\n\n\n\n\n\n\n\n\n\n5.4.3 Two-sample t-test\nThe two-sample t-test (aka, the independent t-test) can be performed using base R functions without the need for additional packages.\n\n\n\n\n\n\nExample\n\n\n\n为研究国产四类新药阿卡波糖胶囊的降血糖效果，某医院用40名II型糖尿病病人进行同期随机对照试验。研究者将这些病人随机等分到试验组(用阿卡波糖胶囊)和对照组(用拜唐苹胶囊)，分别测得试验开始前和8周时的空腹血糖，算得空腹血糖下降值，能否认为该国产四类新药阿卡波糖胶囊与拜唐苹胶囊对空腹血糖的降糖效果不同？\n\n\n\ntwo_sample &lt;- read_csv(\"datasets/ex03-07.csv\")  \n\n#&gt; Rows: 20 Columns: 2\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (2): x1, x2\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nt.test(\n  x = two_sample$x1,\n  y = two_sample$x2,\n) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T) \n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.56\n2.065\n2.625\n-0.642\n0.525\n36.086\n-2.329\n1.209\nWelch Two Sample t-test\ntwo.sided\n\n\n\n\n\n\n\n\n\n5.4.4 Approximate t-test\n进行两小样本均数比较，若两总体方差不等，可采用近似 t 检验:\n例3-7 在上述例3-6国产四类新药阿卡波糖胶囊的降血糖效果研究中，测得用拜唐苹胶囊对照组20例患者和阿卡波糖胶囊试验组20例患者，其8周时糖化血红蛋白HbA1c (%)的下降值见 Table 5.1 。问使用两种不同药物的患者其HbA1c下降值是否相同？\n\n\n\n\nTable 5.1: 阿卡波糖胶囊组和拜唐苹胶囊组HbA1c (%)的下降值\n\n\n\n\n\n\n分组\n\\(n\\)\n\\(\\bar{X}\\)\n\\(S\\)\n\n\n\n\n试验组(阿卡波糖胶囊)\n20\n1.13\n0.70\n\n\n对照组(拜唐苹胶囊)\n20\n1.46\n1.36\n\n\n\n\n\n\n\n\n\nknitr::kable()成功将输出到html的表中的字符渲染为数学符号，其他包函数测试不成功\n\n本例中已知样本均数和方差，标准的t.test()通常用于直接分析数据集而非样本统计量，这里采用DescTools::TTestA()函数。经两样本方差齐性的\\(F\\)检验 (在 Section 5.5 中具体介绍)，两组的总体方差不等，故进行近似 t 检验。\n\nDescTools::TTestA(                              \n  mx = 1.13,\n  my = 1.46,\n  sx = 0.70,\n  sy = 1.36,\n  nx = 20,\n  ny = 20,\n  alternative = \"two.sided\",\n1  var.equal = F\n) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\nvar.equal，指示两个方差是否相等的逻辑变量。如果为FALSE，则使用Welch (或Satterthwaite) 法进行近似 t 检验\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.33\n1.13\n1.46\n-0.965\n0.343\n28.407\n-1.03\n0.37\nWelch Two Sample t-test\ntwo.sided",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Population mean estimation and *t* test</span>"
    ]
  },
  {
    "objectID": "ttest.html#sec-homogeneity-test",
    "href": "ttest.html#sec-homogeneity-test",
    "title": "5  Population mean estimation and t test",
    "section": "5.5 正态和方差齐性检验",
    "text": "5.5 正态和方差齐性检验\n\n5.5.1 正态性检验\n下面对例3-1中的100个样本均数进行正态性检验：\n（一）计算法\n下面分别采用stats::shapiro.test()和DescTools::ShapiroFranciaTest()进行正态性检验：\n\nx &lt;- height_sample |&gt; \n  select(mean) |&gt; \n1  unlist(use.names = F)\n  \n2stats::shapiro.test(x) |&gt;\n  broom::tidy() |&gt; \n  rbind(\n3    DescTools::ShapiroFranciaTest(x) |&gt;\n      broom::tidy()\n  ) |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\n注意：这里须加unlist(use.names = FALSE)，否则会报错\n\n2\n\nShapiro-Wilk方法\n\n3\n\nShapiro-Francia方法\n\n\n\n\n\n\n\nstatistic\np.value\nmethod\n\n\n\n\n0.994\n0.944\nShapiro-Wilk normality test\n\n\n0.993\n0.802\nShapiro-Francia normality test\n\n\n\n\n\n\n\nshapiro.test(x)要求x是数值型变量，所以虽然tibble中的mean是数值型，但不能直接传递给使用shapiro.test(x)，需加一个unlist(x, use.names = FALSE)操作，否则会报错，如下面代码块所示：\n\nx &lt;- height_samples |&gt; \n  select(mean) \n\n#&gt; Error in eval(expr, envir, enclos): object 'height_samples' not found\n\nstats::shapiro.test(x)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.99409, p-value = 0.9444\n\n\n（二）图示法\n图示法主要使用分位数图 (P-P图)和概率图 (Q-Q图)，其中以Q-Q图效率较高。如果分析的数据服从正态分布，则图上的数据点应分布在直线附近，否则数据点偏离直线较远。\n\nx &lt;- height_sample |&gt; \n  select(mean) |&gt; \n  unlist(use.names = F)\n\n\nstats::qqnorm(\n  x,\n  main = \"Q-Q图\",\n  xlab = \"理论分位数\",\n  ylab = \"样本分位数\",\n  datax = T\n) \nstats::qqline(\n  x,\n  datax = T\n)\n\n\n\n\n\n\n\n\n\n\n5.5.2 方差齐性检验\n对例3-6的数据，利用\\(F\\)检验判断两总体空腹血糖下降值的方差是否相等。这里利用DescTools::LeveneTest()进行方差齐性检验\n\ntb &lt;- two_sample |&gt; \n1  pivot_longer(\n    cols = everything(),\n    names_to = \"group\"\n  ) |&gt; \n  mutate(\n2    group = as.factor(group)\n  )\nDescTools::LeveneTest(tb$value, group = tb$group) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\n将原数据框进行拉长转换，以符合DescTools::LeveneTest()参数的要求\n\n2\n\n作为数据分组变量，需转换为因子类型，否则会输出警告\n\n\n\n\n\n\n\nstatistic\np.value\ndf\ndf.residual\n\n\n\n\n0.493\n0.487\n1\n38",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Population mean estimation and *t* test</span>"
    ]
  },
  {
    "objectID": "anova.html",
    "href": "anova.html",
    "title": "6  Analysis of Variance",
    "section": "",
    "text": "6.1 Prerequisite\nlibrary(haven)\nlibrary(tidyverse)",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "anova.html#completely-randomized-design",
    "href": "anova.html#completely-randomized-design",
    "title": "6  Analysis of Variance",
    "section": "6.2 Completely randomized design",
    "text": "6.2 Completely randomized design\n\n\n\n\n\n\nExample\n\n\n\nTo evaluate the efficacy of xanomeline in subjects with mild to moderate Alzheimer’s disease, subjects were randomized equally to placebo, xanomeline low dose, or xanomeline high dose. Subjects applied 2 patches daily and were followed for a total of 26 weeks. Primary efficacy endpoints\n\n\n\n# haven::read_dta(\"datasets/例02-05.dta\") |&gt; \n#   write_csv(\"datasets/ex02-05.csv\")",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "anova.html#section",
    "href": "anova.html#section",
    "title": "6  Analysis of Variance",
    "section": "6.3 ",
    "text": "6.3",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "cox-regression.html",
    "href": "cox-regression.html",
    "title": "11  Cox regression",
    "section": "",
    "text": "Cox regression, also known as Cox proportional hazards regression, is a statistical method used to analyze the time until an event occurs, typically survival time. It is widely used in medical research to explore the relationship between the survival time of patients and one or more predictor variables. Unlike other models, Cox regression does not require assumptions about the baseline hazard function, making it a flexible tool for handling censored data where the exact time of the event may not be known for all subjects.",
    "crumbs": [
      "Basic statistical methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cox regression</span>"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "12  Quarto",
    "section": "",
    "text": "12.1 GitHub Action\n呈现和发布内容有几种不同的方法。下面，我们将提供一个使用 GitHub Actions 和 GitHub Pages 发布内容的指南。",
    "crumbs": [
      "Statistical analysis report",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#github-action",
    "href": "quarto.html#github-action",
    "title": "12  Quarto",
    "section": "",
    "text": "12.1.1 执行代码\n如果你愿意，可以配置一个 GitHub Action 来执行 R 代码作为渲染的一部分。这虽然是最好的方法，但当在 GitHub Actions 等 CI 服务中执行代码时，请考虑以下要求:\n\n你需要在 CI 环境中重新配置所有依赖项（包括 R 以及所需的正确版本的包）。\n如果你的代码需要任何特殊权限（例如访问数据库或网络）， CI 服务器上也需要具备这些权限。\n你的项目可能包含无法轻易执行的文档（例如使用旧版包的几年前的博客文章）。这些文档可能需要单独启用冻结功能，以防止它们在 CI 上执行。\n\n\n\n12.1.2 先决条件\n确保代码可以在 GitHub Action 中执行的最佳方法是为项目使用 renv 虚拟环境。以下是一个完整的 GitHub Action 示例，它安装 R 和 renv.lock 中的包依赖项，然后执行代码并将输出渲染到 GitHub Pages：\n\n\n\n\n\n\nTip\n\n\n\n在 RStudio 左下窗口的 Terminal 选项卡中依次运行以下 Git 命令：\n\ngit remote add origin https://github.com/qbgaoo/r4ms.git\ngit branch -M main\ngit push -u origin main\n\n\n\n在 Quarto 项目中新建文本文件，命名为 publish.yml（当然也可以是其他命字），保存路径为 .github/workflows/publish.yml，在文件中添加如下内容：\non:\n  push:\n    branches: main\n  pull_request:\n    branches: main\n  # to be able to trigger a manual build\n  workflow_dispatch:\n  schedule:\n    # run every day at 11 PM\n    - cron: '0 23 * * *'\n\nname: Render and deploy Book to Github\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Install R\n        uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: '4.4.1'\n\n      - name: Install R Dependencies\n        uses: r-lib/actions/setup-renv@v2\n        with:\n          cache-version: 1\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n这是一个 GitHub Actions 工作流配置文件，保存后将文件提交到 GitHub中，触发文件中的工作流。",
    "crumbs": [
      "Statistical analysis report",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "pilot-project.html",
    "href": "pilot-project.html",
    "title": "13  A case to analyze",
    "section": "",
    "text": "13.1 Datasets\nIn this book, we used publicly available CDISC pilot study data, which is accessible through the CDISC GitHub repository. To streamline the process, we have downloaded all the datasets from the repository and converted them from .xpt format to .sas7bdat format for ease of use and compatibility. Then we stored them in the data/adam/ folder within this project. Additionally, The dataset structure adheres to the CDISC Analysis Data Model (ADaM) standard.\nThe SDTM-ADaM Pilot Project datasets were created to demonstrate the process of converting clinical trial data into formats that comply with the Study Data Tabulation Model (SDTM) and Analysis Data Model (ADaM) standards, which are set by the Clinical Data Interchange Standards Consortium (CDISC). These datasets are used to test, validate, and illustrate how to implement CDISC standards in real-world scenarios, helping pharmaceutical companies and regulatory agencies like the FDA ensure data quality and consistency in clinical trials.\nlibrary(haven)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\n\nadsl |&gt; \n  select(ARM, ITTFL, EFFFL) |&gt; \n  filter(EFFFL == \"Y\") |&gt; \n  group_by(ARM) |&gt; \n  summarise(n = n())\n\n# A tibble: 3 × 2\n  ARM                      n\n  &lt;chr&gt;                &lt;int&gt;\n1 Placebo                 79\n2 Xanomeline High Dose    74\n3 Xanomeline Low Dose     81\nadsl |&gt; \n  glimpse()\n\nRows: 254\nColumns: 48\n$ STUDYID  &lt;chr&gt; \"CDISCPILOT01\", \"CDISCPILOT01\", \"CDISCPILOT01\", \"CDISCPILOT01…\n$ USUBJID  &lt;chr&gt; \"01-701-1015\", \"01-701-1023\", \"01-701-1028\", \"01-701-1033\", \"…\n$ SUBJID   &lt;chr&gt; \"1015\", \"1023\", \"1028\", \"1033\", \"1034\", \"1047\", \"1097\", \"1111…\n$ SITEID   &lt;chr&gt; \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\"…\n$ SITEGR1  &lt;chr&gt; \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\"…\n$ ARM      &lt;chr&gt; \"Placebo\", \"Placebo\", \"Xanomeline High Dose\", \"Xanomeline Low…\n$ TRT01P   &lt;chr&gt; \"Placebo\", \"Placebo\", \"Xanomeline High Dose\", \"Xanomeline Low…\n$ TRT01PN  &lt;dbl&gt; 0, 0, 81, 54, 81, 0, 54, 54, 54, 0, 0, 81, 81, 81, 0, 81, 81,…\n$ TRT01A   &lt;chr&gt; \"Placebo\", \"Placebo\", \"Xanomeline High Dose\", \"Xanomeline Low…\n$ TRT01AN  &lt;dbl&gt; 0, 0, 81, 54, 81, 0, 54, 54, 54, 0, 0, 81, 81, 81, 0, 81, 81,…\n$ TRTSDT   &lt;date&gt; 2014-01-02, 2012-08-05, 2013-07-19, 2014-03-18, 2014-07-01, …\n$ TRTEDT   &lt;date&gt; 2014-07-02, 2012-09-01, 2014-01-14, 2014-03-31, 2014-12-30, …\n$ TRTDUR   &lt;dbl&gt; 182, 28, 180, 14, 183, 26, 190, 10, 55, 182, 183, 183, 38, 18…\n$ AVGDD    &lt;dbl&gt; 0.0, 0.0, 77.7, 54.0, 76.9, 0.0, 54.0, 54.0, 54.0, 0.0, 0.0, …\n$ CUMDOSE  &lt;dbl&gt; 0, 0, 13986, 756, 14067, 0, 10260, 540, 2970, 0, 0, 14121, 26…\n$ AGE      &lt;dbl&gt; 63, 64, 71, 74, 77, 85, 68, 81, 84, 52, 84, 81, 75, 57, 79, 5…\n$ AGEGR1   &lt;chr&gt; \"&lt;65\", \"&lt;65\", \"65-80\", \"65-80\", \"65-80\", \"&gt;80\", \"65-80\", \"&gt;80…\n$ AGEGR1N  &lt;dbl&gt; 1, 1, 2, 2, 2, 3, 2, 3, 3, 1, 3, 3, 2, 1, 2, 1, 2, 2, 2, 3, 2…\n$ AGEU     &lt;chr&gt; \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\"…\n$ RACE     &lt;chr&gt; \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\"…\n$ RACEN    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1…\n$ SEX      &lt;chr&gt; \"F\", \"M\", \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\", \"F\", \"…\n$ ETHNIC   &lt;chr&gt; \"HISPANIC OR LATINO\", \"HISPANIC OR LATINO\", \"NOT HISPANIC OR …\n$ SAFFL    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ ITTFL    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ EFFFL    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ COMP8FL  &lt;chr&gt; \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ COMP16FL &lt;chr&gt; \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"Y\", \"…\n$ COMP24FL &lt;chr&gt; \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"Y\", \"…\n$ DISCONFL &lt;chr&gt; \"\", \"Y\", \"\", \"Y\", \"\", \"Y\", \"\", \"Y\", \"Y\", \"\", \"\", \"\", \"Y\", \"\",…\n$ DSRAEFL  &lt;chr&gt; \"\", \"Y\", \"\", \"\", \"\", \"Y\", \"\", \"Y\", \"Y\", \"\", \"\", \"\", \"Y\", \"\", …\n$ DTHFL    &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ BMIBL    &lt;dbl&gt; 25.1, 30.4, 31.4, 28.8, 26.1, 30.4, 27.3, 23.9, 23.9, 21.9, 2…\n$ BMIBLGR1 &lt;chr&gt; \"25-&lt;30\", \"&gt;=30\", \"&gt;=30\", \"25-&lt;30\", \"25-&lt;30\", \"&gt;=30\", \"25-&lt;30…\n$ HEIGHTBL &lt;dbl&gt; 147.3, 162.6, 177.8, 175.3, 154.9, 148.6, 168.9, 158.2, 181.6…\n$ WEIGHTBL &lt;dbl&gt; 54.4, 80.3, 99.3, 88.5, 62.6, 67.1, 78.0, 59.9, 78.9, 71.2, 7…\n$ EDUCLVL  &lt;dbl&gt; 16, 14, 16, 12, 9, 8, 18, 22, 12, 14, 12, 10, 16, 15, 6, 16, …\n$ DISONSDT &lt;date&gt; 2010-04-30, 2006-03-11, 2009-12-16, 2009-08-02, 2011-09-29, …\n$ DURDIS   &lt;dbl&gt; 43.9, 76.4, 42.8, 55.3, 32.9, 42.0, 99.1, 40.7, 101.9, 44.2, …\n$ DURDSGR1 &lt;chr&gt; \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12…\n$ VISIT1DT &lt;date&gt; 2013-12-26, 2012-07-22, 2013-07-11, 2014-03-10, 2014-06-24, …\n$ RFSTDTC  &lt;chr&gt; \"2014-01-02\", \"2012-08-05\", \"2013-07-19\", \"2014-03-18\", \"2014…\n$ RFENDTC  &lt;chr&gt; \"2014-07-02\", \"2012-09-02\", \"2014-01-14\", \"2014-04-14\", \"2014…\n$ VISNUMEN &lt;dbl&gt; 12, 5, 12, 5, 12, 6, 12, 4, 8, 12, 12, 12, 7, 12, 12, 7, 4, 7…\n$ RFENDT   &lt;date&gt; 2014-07-02, 2012-09-02, 2014-01-14, 2014-04-14, 2014-12-30, …\n$ DCDECOD  &lt;chr&gt; \"COMPLETED\", \"ADVERSE EVENT\", \"COMPLETED\", \"STUDY TERMINATED …\n$ DCREASCD &lt;chr&gt; \"Completed\", \"Adverse Event\", \"Completed\", \"Sponsor Decision\"…\n$ MMSETOT  &lt;dbl&gt; 23, 23, 23, 23, 21, 23, 10, 23, 20, 20, 19, 21, 22, 21, 10, 1…\nglimpse() makes it possible to see every column in a data frame. It’s a little like str() applied to a data frame but it tries to show you as much data as possible.\nOnce you read data in, the first step usually involves transforming it in some way to make it easier to work with in the rest of your analysis. Firstly, we use janitor::clean_names() to turn all column names of data frame adsl into snake case.",
    "crumbs": [
      "Statistical analysis report",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>A case to analyze</span>"
    ]
  },
  {
    "objectID": "basic-stat.html",
    "href": "basic-stat.html",
    "title": "Basic statistical methods",
    "section": "",
    "text": "基本的医学统计方法涵盖了数据的收集、整理、描述、分析和解释，旨在帮助研究者理解疾病的发生、发展、治疗效果及健康状况的分布规律。以下是医学研究中常用的一些基本统计方法：\n\n1. 描述性统计\n\n频率分析：计算各类别或数值出现的频数和百分比。\n集中趋势测量：平均值、中位数和众数，用于描述数据的中心位置。\n离散程度测量：标准差、方差、四分位数间距和极差，反映数据的分散程度。\n\n\n\n2. 推断性统计\n\n参数检验：\n\nt检验：用于比较两组或几组独立或配对样本的均值差异，如学生t检验、配对t检验。\nANOVA（方差分析）：比较多个样本均值是否存在显著差异。\n\n非参数检验：\n\nMann-Whitney U检验（Wilcoxon秩和检验的两样本形式）：适用于连续数据但不符合正态分布的两组样本均值差异检验。\nKruskal-Wallis H检验：多组独立样本的中位数差异检验，适用于非正态分布数据。\n\n卡方检验（Chi-square test）：用于分析分类变量间的关系，如四格表检验。\n\n\n\n3. 回归分析\n\n线性回归：研究一个或多个自变量与一个连续因变量之间的线性关系。\n逻辑回归（Logistic Regression）：适用于因变量为二分类或多元分类的场合，用来估计事件发生概率。\n\n\n\n5. 随机化和抽样\n\n随机化：确保研究的组间可比性。\n抽样技术：包括简单随机抽样、分层抽样、整群抽样等，确保样本代表性。\n\n\n\n6. 误差与功效分析\n\n类型I和II错误的理解，以及统计功效分析，以确定研究设计是否足够强大以检测预期效应。\n\n选择适当的统计方法需依据研究目的、数据类型（定量或定性）、数据分布（正态与否）、样本大小等因素。理解这些基础统计概念和方法对于设计和解读医学研究至关重要。",
    "crumbs": [
      "Basic statistical methods"
    ]
  }
]