[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Medical Statistics",
    "section": "",
    "text": "Welcome\nThe topics of this book line up closely with traditional teaching progression; however, the book also highlights computer-intensive approaches to motivate the more traditional approach. The authors emphasize realistic data and examples and rely on visualization techniques to gather insight. They introduce statistics and R seamlessly, giving students the tools they need to use R and the information they need to navigate the sometimes complex world of statistical computing.\nThis book is created by Quarto and R in RStudio IDE。Quarto is an open-source publishing system that integrates well with R, enabling users to create dynamic documents that combine text, code, and output (like tables and plots) in a single document. It supports R Markdown, allowing the execution of R code within documents and rendering outputs in various formats, such as HTML, PDF, and Word. Quarto is ideal for creating reproducible reports, presentations, and books, especially in academic and research settings where R is extensively used. You can also manage bibliographies, citations, and cross-references easily. Quarto is highly customizable, allowing users to create complex documents with ease, and is often used with GitHub Actions for continuous integration and automated publishing.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "1  Preface",
    "section": "",
    "text": "1.1 Prerequisites\nWe’ve made a few assumptions about what you already know to get the most out of this book. You should have some basic knowledge about medical statistics, and it’s helpful if you have some basic R programming experience already.\nYou need some things to run the code in this book: R, RStudio and some preinstalled R packages. Packages are the fundamental units of reproducible R code. They include reusable functions, documentation that describes how to use them, and sample data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "preface.html#prerequisites",
    "href": "preface.html#prerequisites",
    "title": "1  Preface",
    "section": "",
    "text": "1.1.1 R\nTo download R, go to CRAN, the comprehensive R archive network, https://cloud.r-project.org. A new major version of R comes out once a year, and there are 2-3 minor releases each year. It’s a good idea to update regularly. Upgrading can be a bit of a hassle, especially for major versions that require you to re-install all your packages, but putting it off only makes it worse. We recommend R 4.4.1 or later for this book.\n\n\n1.1.2 RStudio\nRStudio is an integrated development environment, or IDE, for R programming, which you can download from https://posit.co/download/rstudio-desktop/. RStudio is updated a couple of times a year, and it will automatically let you know when a new version is out, so there’s no need to check back. It’s a good idea to upgrade regularly to take advantage of the latest and greatest features. For this book, make sure you have at least RStudio 2024.04.2.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "preface.html#running-r-code",
    "href": "preface.html#running-r-code",
    "title": "1  Preface",
    "section": "1.2 Running R code",
    "text": "1.2 Running R code\nThe previous section showed you several examples of running R code. The code in the book looks like this:\n\n1 + 2\n\n#&gt; [1] 3\n\n\nIf you run the same code in your local console, it will look like this:\n&gt; 1 + 2\n[1] 3\nThere are two main differences. In your console, you type after the &gt;, called the prompt; we don’t show the prompt in the book. In the book, the output is commented out with #&gt;; in your console, it appears directly after your code. These two differences mean that if you’re working with an electronic version of the book, you can easily copy code out of the book and paste it into the console.\nThroughout the book, we use a consistent set of conventions to refer to code:\n\nFunctions are displayed in a code font and followed by parentheses, like sum() or mean().\nOther R objects (such as data or function arguments) are in a code font, without parentheses, like flights or x.\nSometimes, to make it clear which package an object comes from, we’ll use the package name followed by two colons, like dplyr::mutate() or nycflights13::flights. This is also valid R code.\nTo improves readability, variable names and function names are named using snake case.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "preface.html#colophon",
    "href": "preface.html#colophon",
    "title": "1  Preface",
    "section": "1.3 Colophon",
    "text": "1.3 Colophon\nThe book is written by Quarto, an online version of it is available at https://qbgaoo.github.io/r4ms/. It will continue to evolve in between reprints of the physical book. The source of the book is available at https://qbgaoo.github.io/r4ms/.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 Medical statistics\nMedical statistics is the science of applying statistical techniques and principles to analyze data related to health, disease, treatment effectiveness, and public health issues. It involves the systematic collection, organization, description, and inference of health-related data to assist healthcare professionals in making evidence-based, scientific decisions.\nKey Components:\n1. Data Collection: Gathering health-related data systematically through experiments, observational studies, or clinical trials.\n2. Data Organization and Description: Using statistical measures, such as means, variances, and frequency distributions, to describe and summarize the basic characteristics of the data.\n3. Data Analysis: Applying inferential statistical methods, such as hypothesis testing, regression analysis, and analysis of variance (ANOVA), to uncover patterns and causal relationships in the data.\n4. Interpretation of Results: Applying the results of statistical analyses to the medical field, explaining the occurrence and progression of diseases, the effectiveness of treatments, and providing evidence-based support for clinical decisions and public health policies.\nMedical statistics is widely used in medical research, the design of clinical trials, the evaluation of diagnostic tests, the comparison of treatment outcomes, and the epidemiological study of diseases.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#population-and-sample",
    "href": "intro.html#population-and-sample",
    "title": "2  Introduction",
    "section": "2.2 Population and sample",
    "text": "2.2 Population and sample\nPopulation and sample are fundamental concepts in statistics, and they are key to understanding data analysis, particularly in the context of statistical inference.\n\n2.2.1 Population\nA population includes all members of a defined group that we are studying or collecting information on for data-driven decisions. The population represents the entire group of interest, which could be people, objects, events, or measurements.\nExamples: All adults living in a particular country. All patients treated for a particular condition in a hospital over a decade. • Characteristics:\nParameters: The numerical characteristics of a population are called parameters (e.g., population mean, population standard deviation).\nSize: The population can be finite (e.g., all students in a school) or infinite (e.g., all possible outcomes of rolling a die).\n\n\n2.2.2 Sample\nA sample is a subset of the population selected for study. It is often impractical or impossible to study an entire population, so researchers use a sample to draw conclusions about the population.\nExamples: 1,000 randomly selected adults from a country. 200 patients selected from the hospital’s records.\nStatistics: The numerical characteristics of a sample are called statistics (e.g., sample mean, sample standard deviation).\nSize: The size of the sample (denoted as n) is always smaller than the population size (denoted as N).\n\n\n2.2.3 Relationship between population and sample\nSampling: The process of selecting a sample from a population is called sampling. It is crucial that the sample is representative of the population to ensure that the conclusions drawn from the sample can be generalized to the population.\nInference: Statistical inference involves making predictions or generalizations about a population based on information from a sample. This is done using various statistical methods, including estimation and hypothesis testing.\nBias and Variability: A sample might not perfectly represent the population due to sampling bias or variability. Researchers use random sampling techniques to minimize these issues and improve the reliability of the inference.\nPractical Example\nImagine you want to study the average height of all adult women in a country (population). Measuring the height of every woman in the country would be impractical, so instead, you randomly select 500 women (sample) and measure their heights. The average height of these 500 women is a statistic. You then use this statistic to estimate the parameter—the average height of all adult women in the country.\nKey Points to Remember\nPopulation: Entire group of interest; parameters describe it.\nSample: Subset of the population; statistics describe it.\nInference: Drawing conclusions about the population based on sample data.\nRepresentativeness: A sample should represent the population to ensure valid inferences.\nUnderstanding the distinction between population and sample is essential for conducting valid and reliable statistical analyses.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#data",
    "href": "intro.html#data",
    "title": "2  Introduction",
    "section": "2.3 Data",
    "text": "2.3 Data\nIn statistics, data can be classified into different types based on various characteristics. Understanding these data types is crucial for selecting appropriate statistical methods and accurately interpreting results. Below are the main types of data:\n\n2.3.1 Quantitative data\nQuantitative data (numerical data) refers to data that can be measured and expressed numerically. This type of data is critical in the medical field as it allows for precise measurements, comparisons, and statistical analysis, ultimately leading to better understanding, diagnosis, treatment, and prevention of diseases. Quantitative data can be further classified into two main types:\n1. Discrete Data\nDiscrete data consist of distinct, separate values that are countable. These values are typically whole numbers, and there is no intermediate value between them.\nExamples:\nNumber of patients: The number of patients admitted to a hospital.\nNumber of medications: The number of medications a patient is taking.\nNumber of occurrences: The number of heartbeats per minute (heart rate).\n2. Continuous Data\nContinuous data can take any value within a given range. These data represent measurements and can have decimal places, meaning they are not restricted to whole numbers.\nExamples:\nBlood pressure: Systolic and diastolic blood pressure measurements (e.g., 120/80 mmHg).\nBody temperature: Body temperature measured in degrees Celsius or Fahrenheit (e.g., 36.6°C).\nCholesterol levels: Blood cholesterol levels measured in milligrams per deciliter (e.g., 180 mg/dL).\nQuantitative data is fundamental in many areas of medicine:\n\nDiagnosis: • Quantitative measurements such as blood pressure, blood glucose levels, and cholesterol levels are used to diagnose conditions like hypertension, diabetes, and hyperlipidemia. 2. Treatment Monitoring: • Quantitative data is crucial for monitoring treatment effectiveness. For example, changes in tumor size (measured in millimeters or centimeters) can indicate whether cancer treatment is effective. 3. Epidemiology: • Quantitative data is used to track disease incidence and prevalence rates, mortality rates, and other public health indicators. • Example: Tracking the number of new COVID-19 cases per day during a pandemic. 4. Clinical Research: • In clinical trials, quantitative data is collected to assess the safety and efficacy of new drugs or treatments. • Example: Measuring the reduction in blood pressure in participants taking an antihypertensive drug. 5. Medical Imaging: • Quantitative data is used in medical imaging to measure organ size, tumor volume, and other anatomical features. • Example: Measuring the size of a kidney stone on an ultrasound image.\n\nStatistical Analysis of Quantitative Data in Medicine\nQuantitative data allows for a variety of statistical analyses, including:\n\nDescriptive Statistics: • Mean: The average value (e.g., average heart rate of a group of patients). • Median: The middle value when data is ordered (e.g., median age of patients in a study). • Standard Deviation: A measure of the variability or spread of data (e.g., variability in blood pressure readings).\nInferential Statistics: • t-tests and ANOVA: Used to compare means between two or more groups. • Regression Analysis: Used to model the relationship between a dependent variable and one or more independent variables. • Correlation: Used to assess the strength and direction of the relationship between two continuous variables.\nProbability and Distributions: • Quantitative data often follows specific statistical distributions (e.g., normal distribution), which are used in probability and inferential statistics.\n\nExamples of Quantitative Data in Medical Practice\nVital Signs Monitoring: • Continuous monitoring of heart rate, blood pressure, and oxygen saturation levels in critically ill patients. • Laboratory Tests: • Quantitative measurement of blood glucose levels, complete blood count (CBC), and electrolyte levels. • Growth and Development: • Tracking height, weight, and head circumference in pediatric patients over time to assess growth and development. • Pharmacokinetics: • Measuring drug concentrations in the blood over time to understand absorption, distribution, metabolism, and excretion.\nApplication of Quantitative Data in Medical Research\n\nRandomized Controlled Trials (RCTs): • Quantitative data is used to compare the effectiveness of new treatments or interventions with standard care or placebo. • Example: Measuring the reduction in blood pressure in patients receiving a new antihypertensive drug versus a placebo.\nLongitudinal Studies: • Quantitative data is collected over time to study changes in health outcomes, risk factors, or disease progression. • Example: Tracking changes in lung function in smokers versus non-smokers over several years.\nHealth Economics: • Quantitative data is used to evaluate the cost-effectiveness of medical interventions, including cost per quality-adjusted life year (QALY) gained. • Example: Calculating the cost-effectiveness of a new cancer treatment based on survival rates and costs.\n\nQuantitative data is a cornerstone of medical science, providing the foundation for diagnosis, treatment, research, and public health. Its ability to be precisely measured and analyzed makes it indispensable for advancing medical knowledge, improving patient care, and making informed decisions in healthcare.\n\n\n2.3.2 Qualitative data (Categorical data)\nQualitative data in medicine refers to non-numerical data that represent categories or groups. Unlike quantitative data, which deals with numbers and measurements, qualitative data describes characteristics or attributes that can be used to classify individuals, objects, or events into distinct groups. This type of data is crucial in medical research and practice for understanding patient demographics, disease classifications, and treatment outcomes. ain types:\n1. Nominal Data\nNominal data consists of categories that do not have a natural order or ranking. These categories are mutually exclusive, meaning that an individual or event can belong to only one category.\nBlood Type: Categories like A, B, AB, and O.\nGender: Male, Female, Other.\nPresence or Absence of a Condition: Yes/No responses (e.g., presence of hypertension).\n\n\n2.3.3 Ordinal Data\nOrdinal data consists of categories that have a meaningful order or ranking, but the intervals between the categories are not necessarily equal or meaningful.\nSeverity of Disease: Mild, Moderate, Severe.\nPain Scale: Numeric rating scale (e.g., 0–10), where 0 is no pain and 10 is the worst pain imaginable.\nStage of Cancer: Stages I, II, III, IV.\nQualitative data plays a vital role in various aspects:\n\nPatient Demographics:\n\nCategorization: Patients are often categorized based on attributes like age group, gender, race, and ethnicity, which are critical for understanding the distribution of diseases and tailoring medical interventions.\nExample: A study may categorize patients by age group (e.g., children, adults, elderly) to analyze how a particular disease affects different age groups.\n\nDisease Classification:\n\nDiagnosis: Diseases are classified into categories based on symptoms, genetic markers, or other clinical criteria. This classification helps in diagnosing, treating, and researching diseases.\nExample: Types of diabetes (Type 1, Type 2, Gestational Diabetes) are categorical variables that guide treatment plans.\n\nTreatment Outcomes:\n\nOutcome Measures: Treatment outcomes can be categorized as successful/unsuccessful, improved/no improvement, or recurrence/no recurrence. These qualitative outcomes are essential for evaluating the effectiveness of treatments.\nExample: A study on cancer treatment might categorize outcomes as “complete remission,” “partial remission,” or “no response.”\n\nQuality of Life and Patient Satisfaction:\n\nSurveys and Questionnaires: Patient satisfaction surveys and quality of life assessments often use ordinal scales (e.g., very satisfied, satisfied, neutral, dissatisfied, very dissatisfied) to gather qualitative data on patient experiences.\nExample: A patient satisfaction survey may categorize responses to a question about hospital care quality into five levels, from “very poor” to “excellent.”\n\n\nStatistical Analysis of Qualitative Data\n\nFrequency and Proportion: The most basic analysis involves counting the number of occurrences in each category and expressing them as frequencies or proportions (percentages).\nExample: Proportion of patients with a specific blood type in a population.\nChi-Square Tests: Used to determine if there is a significant association between two categorical variables.\nExample: Assessing the relationship between smoking status (smoker, non-smoker) and lung cancer diagnosis (yes, no).\n\n\n\nLogistic Regression: Used for modeling the probability of a binary outcome based on one or more predictor variables.\nExample: Predicting the likelihood of a disease relapse based on treatment type and other categorical factors.\nCross-Tabulation: A method used to examine the relationship between two or more categorical variables by displaying the data in a matrix format.\nExample: Cross-tabulating the relationship between gender and the prevalence of a specific medical condition.\n\nApplications in Medical Research\n\nEpidemiology:\n\nResearchers often use qualitative data to study the distribution and determinants of health-related states in populations.\nExample: Categorizing patients by exposure to a risk factor (e.g., exposure to asbestos: yes/no) and examining its relationship with disease occurrence.\n\nClinical Trials:\n\nClinical trials use qualitative data to classify participants, monitor treatment adherence, and assess treatment responses.\nExample: Categorizing patients based on their response to a new drug as “responsive,” “partially responsive,” or “non-responsive.”\n\nPublic Health:\n\nPublic health studies often categorize populations based on demographic factors to identify health disparities and target interventions.\nExample: Identifying vaccination rates across different ethnic groups to improve immunization programs.\nQualitative data is essential in the medical field for categorizing and analyzing various aspects of health and disease. It provides the basis for understanding patterns, making clinical decisions, and conducting research that ultimately improves patient care. Properly collecting, analyzing, and interpreting qualitative data ensures that medical interventions are tailored to the specific needs of patients and populations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html",
    "href": "quat-data-stat-desc.html",
    "title": "3  Statistical description of quantitative data",
    "section": "",
    "text": "3.1 Prerequisite\nSetting up the required R packages.\nlibrary(tidyverse)\nDownload data\nClick on the download button above to download as a .csv file. Save it in your working directory and import the data file into R using the code below.\nrbc &lt;- read_csv(\"datasets/ex02-01.csv\")\n\n#&gt; Rows: 138 Columns: 1\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (1): rbc\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nHere we use the read_csv() function. The first argument is the most important: the path to the file. You can think about the path as the address of the file. The code above will work if you have a ex02-01.csv file in the datasets folder of your project.\nWhen you run read_csv(), it prints out a message telling you the number of rows and columns of data, the delimiter that was used, and the column specifications (names of columns organized by the type of data the column contains). It also prints out some information about retrieving the full column specification and how to quiet this message.\nThe data file has only one column with name rbc. Let’s check if there are some missing values present in it.\nrbc |&gt; \n  anyNA()\n\n#&gt; [1] FALSE\nThe output FALSE indicates no missing values is present.",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#prerequisite",
    "href": "quat-data-stat-desc.html#prerequisite",
    "title": "3  Statistical description of quantitative data",
    "section": "",
    "text": "Example 1: \nSome researchers used a random sampling method to examine the red blood cell counts of 138 normal adult women. The measuring results are saved in a data file. Please use the data to create a frequency distribution table.",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#visualization",
    "href": "quat-data-stat-desc.html#visualization",
    "title": "3  Statistical description of quantitative data",
    "section": "3.2 Visualization",
    "text": "3.2 Visualization\n\n3.2.1 Frequency table\nA frequency table mentioned here is a statistical tool that organizes data into intervals and lists the number of frequency in each interval. It helps summarize large dataset by showing how often each value or range of values occurs, making it easier to identify trends and the overall distribution of the data. This table is often used in conjunction with visual tools like histogram to enhance data interpretation.\nHere is the steps for creating a frequency table for continuous variables.\n\nComputing the minimum and maximum of the variable.\n\n\nmin_rbc &lt;- rbc |&gt; \n  min()\n\nmax_rbc &lt;- rbc |&gt; \n  max()\n\n\nDetermining the number of intervals. The number of intervals is typically between 10 and 15; here, we adopt 10. The seq() function is used to obtain upper and lower limits of the intervals.\n\n\nbins = 12\nbreaks &lt;- seq(min_rbc, max_rbc, length.out = bins + 1)\nbreaks\n\n#&gt;  [1] 3.070000 3.269167 3.468333 3.667500 3.866667 4.065833 4.265000 4.464167\n#&gt;  [9] 4.663333 4.862500 5.061667 5.260833 5.460000\n\n\n\nUsing the cut() function to dive each data into their respective intervals.\n\n\ncut(pull(rbc), breaks = breaks, include.lowest = T, right = F) |&gt; \n  head(40)\n\n#&gt;  [1] [3.87,4.07) [4.07,4.26) [4.26,4.46) [3.47,3.67) [5.06,5.26) [3.87,4.07)\n#&gt;  [7] [4.26,4.46) [3.67,3.87) [4.66,4.86) [4.07,4.26) [4.46,4.66) [4.07,4.26)\n#&gt; [13] [3.67,3.87) [4.07,4.26) [4.26,4.46) [3.07,3.27) [4.86,5.06) [3.87,4.07)\n#&gt; [19] [4.26,4.46) [3.47,3.67) [4.46,4.66) [3.87,4.07) [4.46,4.66) [4.07,4.26)\n#&gt; [25] [4.46,4.66) [3.87,4.07) [4.26,4.46) [3.47,3.67) [4.86,5.06) [3.87,4.07)\n#&gt; [31] [4.26,4.46) [4.07,4.26) [4.66,4.86) [4.07,4.26) [4.46,4.66) [4.07,4.26)\n#&gt; [37] [4.46,4.66) [3.67,3.87) [3.87,4.07) [4.07,4.26)\n#&gt; 12 Levels: [3.07,3.27) [3.27,3.47) [3.47,3.67) [3.67,3.87) ... [5.26,5.46]\n\n\n\nGenerating the frequency table.\n\n\ncut(pull(rbc), breaks = breaks, include.lowest = T, right = F) |&gt;\n  table() |&gt; \n  knitr::kable(col.names = c(\"interval\", \"freq\"), align = \"c\")\n\n\n\n\ninterval\nfreq\n\n\n\n\n[3.07,3.27)\n2\n\n\n[3.27,3.47)\n3\n\n\n[3.47,3.67)\n9\n\n\n[3.67,3.87)\n14\n\n\n[3.87,4.07)\n22\n\n\n[4.07,4.26)\n30\n\n\n[4.26,4.46)\n21\n\n\n[4.46,4.66)\n15\n\n\n[4.66,4.86)\n10\n\n\n[4.86,5.06)\n6\n\n\n[5.06,5.26)\n4\n\n\n[5.26,5.46]\n2\n\n\n\n\n\n\n\n3.2.2 Frequency histogram\nA frequency histogram is a graphical representation of a frequency table. It displays the distribution of numerical variales by showing the frequency (count) of a value within specific intervals (bins) on the x-axis, with the y-axis representing the frequency. Each bar in the histogram corresponds to an interval, and the height of the bar indicates how many valuess fall within that range. This visual tool is useful for quickly assessing the shape, spread, and central tendency of the data distribution.\nHere we supply two methods to plot a histogram.\n\nbaseggplot2\n\n\n\nhist(\n  x              = pull(rbc), \n  breaks         = breaks, \n  freq           = T,\n  right          = F, \n  col            = \"skyblue\", \n  include.lowest = T,\n  main           = \" \",\n  xlab           = \"Maximum heart rate\",\n  ylab           = \"Frequency\",\n  ylim           = c(0, 32),\n  labels         = T\n)\n\n\n\n\n\n\n\n\n\n\n\nrbc |&gt; \n  ggplot(aes(x = rbc)) +\n  geom_histogram(\n    fill   = \"skyblue\", \n    stat   = \"bin\",\n    color  = \"black\",\n    breaks = breaks,\n    closed = \"left\"\n  ) +\n  stat_bin(\n    geom   = \"text\", \n    aes(label = after_stat(count)),\n    breaks = breaks, \n    closed = \"left\",\n    size   = 4,\n    vjust  = - 0.3\n  ) +\n  labs(x = \"Maximum heart rate\", y = \"Frequency\") +\n  theme(\n    axis.title.x     = element_text(size = 12), \n    axis.title.y     = element_text(size = 12), \n    axis.text.x      = element_text(size = 11),  \n    axis.text.y      = element_text(size = 11),\n    panel.background = element_blank(),        \n    axis.line        = element_line(color = \"black\") \n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Call Shiny App\n\nLaunch Shiny App\n\n\n\nlibrary(shiny)\n\n# Define function that trigger a Shiny App\nobserveEvent(input$shiny_trigger, {\n  runApp(\"shiny/histogram\", launch.browser = F)\n})",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#measures-of-central-tendency",
    "href": "quat-data-stat-desc.html#measures-of-central-tendency",
    "title": "3  Statistical description of quantitative data",
    "section": "3.3 Measures of central tendency",
    "text": "3.3 Measures of central tendency\nCentral tendency is a statistical concept that refers to the measure of the center or typical value in a data set. It provides a summary of the data with a single value that represents the middle or average of the data. The most common measures of central tendency are:\n\n3.3.1 Mean\nThe arithmetic average of all values. It’s calculated by summing all the values and dividing by the number of values.\nFor a population:\n\\[\n\\mu = \\frac{\\sum X_i}{N}\n\\]\nFor a sample:\n\\[\n\\bar{X} = \\frac{\\sum X_i}{n}\n\\]\nwhere \\(X_i\\) represents each value, and \\(N\\) and \\(n\\) are the sizes of the population and sample, respectively.\n\nrbc |&gt; \n  pull() |&gt; \n  mean()\n\n#&gt; [1] 4.227029\n\n\n\n\n3.3.2 Median\nThe middle value in a data set when the values are sorted in ascending order. If there is an even number of values, the median is the average of the two middle values. Unlike the mean, the median is not affected by outliers or skewed data, making it a robust indicator of central tendency. To find the median:\n\nSort the data set.\nIf the number of observations N is odd, the median is the middle value.\nIf N is even, the median is the average of the two central values.\n\n\nrbc |&gt; \n  pull() |&gt; \n  median()\n\n#&gt; [1] 4.23",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "quat-data-stat-desc.html#measures-of-dispersion",
    "href": "quat-data-stat-desc.html#measures-of-dispersion",
    "title": "3  Statistical description of quantitative data",
    "section": "3.4 Measures of dispersion",
    "text": "3.4 Measures of dispersion\nDispersion or variability, describe the spread or dispersion of data points in a data set. They provide insight into how much individual data points differ from the central value (mean, median, etc.). Common measures of dispersion include:\n\n3.4.1 Range\nThe difference between the maximum and minimum values in the data set.\n\\[\n\\text{range} = \\text{max} - \\text{min}\n\\]\n\nrange(rbc) |&gt; \n  diff()\n\n#&gt; [1] 2.39\n\n\n\n\n3.4.2 Interquartile Range (IQR)\nThe range of the middle 50% of the data, calculated as the difference between the 75th percentile (Q3) and the 25th percentile (Q1).\n\\[\n\\text{IQR} = Q3 - Q1\n\\]\nYou can directly use the IQR() function to get IQR.\n\nrbc |&gt; \n  pull() |&gt; \n  IQR()\n\n#&gt; [1] 0.565\n\n\n\n\n3.4.3 Variance\nMeasures the average squared deviation of each data point from the mean.\nFor a population:\n\\[\n\\sigma^2 = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\mu)^2\n\\]\nFor a sample:\n\\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2\n\\]\nwhere \\(\\mu\\) is the population mean, \\(\\bar{X}\\) is the sample mean, \\(X_i\\) represents each value, and \\(N\\) and \\(n\\) are are the sizes of the population and sample, respectively.\nYou can directly use the var() function to get variance.\n\nrbc |&gt; \n  pull() |&gt; \n  var()\n\n#&gt; [1] 0.1986751\n\n\n\n\n3.4.4 Standard deviation\nThe square root of the variance, providing a measure of spread in the same units as the data.\nFor a population:\n\\[\n\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (X_i - \\mu)^2}\n\\]\nFor a sample:\n\\[\nS = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2}\n\\]\nYou can directly use the sd() function to get standard deviation.\n\nrbc |&gt; \n  pull() |&gt; \n  sd()\n\n#&gt; [1] 0.4457298\n\n\n\n\n3.4.5 Coefficient of Variation (CV)\nThe ratio of the standard deviation to the mean, expressed as a percentage, useful for comparing variability between variables with different units or scales.\nFor a population:\n\\[\n\\text{CV} = \\frac{\\sigma}{\\mu} \\times 100%\n\\]\nwhere \\(\\sigma\\) is the standard deviation and \\(\\mu\\) is the mean of a population.\nFor a sample:\n\\[\n\\text{CV} = \\frac{S}{\\bar{X}} \\times 100%\n\\]\nwhere \\(S\\) is the standard deviation and \\(\\bar{X}\\) is the mean of a sample.\n\nmean &lt;- rbc |&gt; \n  pull() |&gt; \n  mean()\n\nsd &lt;- rbc |&gt; \n  pull() |&gt; \n  sd()\n\nsd / mean * 100\n\n#&gt; [1] 10.54475",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical description of quantitative data</span>"
    ]
  },
  {
    "objectID": "normal-distribution.html",
    "href": "normal-distribution.html",
    "title": "4  Normal distribution and medical reference range",
    "section": "",
    "text": "4.1 Prerequisite\nSetting up the required R packages in this chapter.\nlibrary(tidyverse)\nlibrary(nortest)\nlibrary(scales)\nlibrary(e1071)",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normal distribution and medical reference range</span>"
    ]
  },
  {
    "objectID": "normal-distribution.html#normal-distribution",
    "href": "normal-distribution.html#normal-distribution",
    "title": "4  Normal distribution and medical reference range",
    "section": "4.2 Normal distribution",
    "text": "4.2 Normal distribution\nThe probability density function of a normal distribution is given by the formula:\n\\[f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\nwhere \\(x\\) is the variable, \\(\\mu\\) is the mean, and \\(\\sigma\\) is the standard deviation. The \\(\\mu\\) and \\(\\sigma\\) are two parameters of the distribution. The mean \\(\\mu\\) is a location parameter, which defines the central position, as shown in Figure 4.1 . The standard deviation \\(\\sigma\\) is the shape parameter, which defines the width and height of the distribution, as shown in Figure 4.2 .\n\n\n\n\n\n\n\n\nFigure 4.1: The normal curve with different means\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.2: The normal curve with different standard deviation\n\n\n\n\n\nThe cumulative distribution function is the probability that a normal random variable \\(x\\) will be less than or equal to a given value x, which is defined by the formula:\n\\[F(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\int_{-\\infty}^x e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]The area under the curve of a normal distribution over a specific interval represents the probability that the random variable falls within that interval. This is computed using the cumulative distribution function.\nIn R, you can calculate the area under the curve between two points using the pnorm() function.\n\nExample 1: \nCalculating the area under the standard normal curve between -1.96 and 1.96.\n\n\narea_under_curve &lt;- pnorm(1.96, mean = 0, sd = 1) - pnorm(-1.96, mean = 0, sd = 1)\narea_under_curve\n\n#&gt; [1] 0.9500042\n\n\n\n4.2.1 Visualizing the area under the normal curve\nYou can use ggplot2 package in R to plot the normal distribution curve and shade the area under the curve. Here is example to shade the area of the left and right tails.\n\n\n\n\n\n\n\n\n\n\nExample 2: \nSome researchers used a random sampling method to examine the red blood cell count of 55 normal adults. The measuring results are saved in a .csv file. Please analyze its normality.\n\n  Download data \nYou can click on the download button above to download and the save it in your own folder. Here we import the data file into R and assign to a tibble named rbc.\n\nrbc &lt;- read_csv(\"datasets/ex03-01.csv\")\n\n#&gt; Rows: 55 Columns: 1\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (1): rbc\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTest of normality is used to determine if a variable is well-modeled by a normal distribution. This is an important assumption for many statistical tests. Histogram () can be used as a visual tool to assess whether a variable follows a normal distribution, but it should be used with caution due to the reasons below:\n\nFor a small sample data, the histogram might not provide a clear picture of the distribution, making it harder to assess normality. With larger samples, the histogram gives a better indication but may still be misleading.\nThe appearance of the histogram can change significantly depending on the number of bins (or the bin width). Too few bins might obscure important features of the data, while too many bins might introduce noise.\nThe interpretation of a histogram is somewhat subjective. Two people might look at the same histogram and draw different conclusions about normality.\n\nSince histogram can sometimes be misleading or ambiguous, it’s good practice to use it alongside other methods:\n\nNormality Tests\n\nShapiro-Wilk test: Best for small to medium-sized data.\nShapiro-Francia test: A variation of the Shapiro-Wilk test. It is generally more appropriate for dealing with larger sample size data compared to the Shapiro-Wilk test, particularly for data that is expected to be normally distributed.\nAnderson-Darling test: Gives more weight to the tails of the distribution.\n\nStatistical tests can provide a more formal assessment of normality, though they also have limitations and can be sensitive to sample size.\nQ-Q Plot (Quantile-Quantile Plot)\nThis is a more reliable visual tool that plots the quantiles of the data against the quantiles of a theoretical normal distribution. Always useful as a supplementary method.\n\n\n\n4.2.2 Normality Tests\nHere we perform the Shapiro-Wilk test using shapiro.test(), which lies in the stats package of base R. The Shapiro-Francia test and Anderson-Darling test are performed by sf.test() and ad.test(), respectively. Both of them come from the nortest package, which need to be installed beforehand.\n\nShapiro-WilkShapiro-FranciaAnderson-Darling\n\n\n\nrbc |&gt; \n  pull() |&gt; \n  shapiro.test()\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  pull(rbc)\n#&gt; W = 0.98527, p-value = 0.7343\n\n\n\n\n\nrbc |&gt; \n  pull() |&gt; \n  sf.test()\n\n#&gt; \n#&gt;  Shapiro-Francia normality test\n#&gt; \n#&gt; data:  pull(rbc)\n#&gt; W = 0.98475, p-value = 0.6158\n\n\n\n\n\nrbc |&gt; \n  pull() |&gt; \n  ad.test()\n\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  pull(rbc)\n#&gt; A = 0.2194, p-value = 0.8284\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIf the p-value is greater than 0.05, the data is normally distributed (fail to reject the null hypothesis).\nIf the p-value is less than 0.05, the data is not normally distributed (reject the null hypothesis).\n\n\n\n\n\n4.2.3 Q-Q Plot\nVisual inspection of the data can be very informative. You can create a Q-Q Plot using qqnorm() function. More, you can add a line to a theoretically normal quantile-quantile plot by qqline(), which passes through the first and third quartiles by default. These two functions can be found from the stats package of base R.\n\nrbc |&gt; \n  pull() |&gt; \n  qqnorm(main = \"\", datax = T)\n\nrbc |&gt; \n  pull() |&gt; \n  qqline(datax = T)\n\n\n\n\n\n\n\n\nAlternatively you can use the ggplot2 package to create a Q-Q plot, which has more customization and flexibility. Here is an example.\n\nrbc |&gt;\n  ggplot(aes(sample = rbc)) +\n  geom_qq(shape = 1, size = 2.3) +\n  geom_qq_line() +\n  labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  coord_flip() +\n  theme(\n    axis.text  = element_text(size = 12),\n    axis.title = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIf the data points fall approximately along the reference line in the Q-Q plot, the data is likely normally distributed.\nSignificant deviations from the line indicate departures from normality.",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normal distribution and medical reference range</span>"
    ]
  },
  {
    "objectID": "normal-distribution.html#medical-reference-range",
    "href": "normal-distribution.html#medical-reference-range",
    "title": "4  Normal distribution and medical reference range",
    "section": "4.3 Medical reference range",
    "text": "4.3 Medical reference range\nA medical reference range is the set of values that a medical test result falls within for a healthy population. These ranges are used by healthcare providers to interpret laboratory results and determine whether a patient’s test results are normal or indicate a potential health issue.\n\n4.3.1 Establishment\nReference ranges are typically established by testing a large sample of healthy individuals and determining the range within which a certain percentage (often 95%) of results fall. The middle 95% of the population’s values are considered the reference range, meaning that 2.5% of healthy individuals might naturally have results slightly below this range and another 2.5% slightly above it.\n\n\n4.3.2 Results interpretation\nA test result that falls within the reference range is usually considered normal. A result outside the reference range might indicate an abnormal condition, but this must be interpreted in the context of the patient’s overall health, symptoms, and medical history. Not all out-of-range results indicate disease; they might be normal for a specific individual due to factors like temporary stress, diet, or exercise.\n\n\n4.3.3 Considerations\nVariability: Reference ranges are not absolute; what is normal for one individual may not be normal for another, especially at the edges of the range.\nClinical Context: Doctors consider a variety of factors, including patient history and symptoms, when interpreting test results. An out-of-range result may warrant further testing or a different interpretation based on the clinical context. •\nReference Range Updates: Reference ranges may be updated as new research and technologies emerge, so staying informed about the latest standards is important for accurate diagnosis and treatment.\n\nmed_ref_range &lt;- rbc |&gt; \n  pull() |&gt; \n  quantile(probs = c(0.025, 0.975)) |&gt; \n  round(digits = 2) |&gt; \n  print()\n\n#&gt;  2.5% 97.5% \n#&gt;  4.12  6.07\n\n\nThe result indicates that the 95% medical reference range for the maximum heart rate in normal individuals is: (4.12, 6.07).",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Normal distribution and medical reference range</span>"
    ]
  },
  {
    "objectID": "ttest.html",
    "href": "ttest.html",
    "title": "6  t-test",
    "section": "",
    "text": "6.1 Prerequisites\nlibrary(tidyverse)\nlibrary(kableExtra)",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-distribution",
    "href": "ttest.html#t-distribution",
    "title": "6  t-test",
    "section": "6.2 t distribution",
    "text": "6.2 t distribution\nThe t-distribution, also known as Student’s t-distribution, is a probability distribution that is used in statistics when estimating population parameters when the sample size is small and/or the population variance is unknown. It’s especially important in hypothesis testing, confidence intervals, and regression analysis.\nFor a sample mean \\(\\bar{X}\\) , sample standard deviation \\(S\\) , and sample size \\(n\\) , the t-statistic is calculated as:\n\\[\nt = \\frac{\\bar{X} - \\mu}{S / \\sqrt{n}}\n\\]\nWhere \\(\\mu\\) is the hypothesized population mean.\nVisual Representation:\nThe t-distribution can be plotted to show how it compares with the normal distribution. It would have thicker tails, indicating a higher probability of values further from the mean, especially with smaller degrees of freedom. As degrees of freedom increase, the t-distribution curve will converge toward the standard normal distribution curve.\n\ntibble(\n  x  = seq(-4, 4, length.out = 500),\n  y1 = dt(x, df = 1),\n  y2 = dt(x, df = 5),\n  y3 = dt(x, df = Inf)\n) |&gt; \n  pivot_longer(\n    cols      = contains(\"y\"),\n    values_to = \"density\",\n    names_to  = \"group\"\n  ) |&gt; \n  ggplot(aes(x = x, y = density, linetype = group)) +\n  geom_line() +\n  scale_linetype_manual(\n    name   = \"\",\n    values = c(\"dashed\", \"solid\", \"dotdash\"),\n    labels = c(\"df = 1\", \"df = 5\", \"df = Inf\")\n  ) +\n  theme(\n    axis.text   = element_text(size = 12),\n    axis.title  = element_text(size = 12),\n    legend.text = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n6.2.1 Key characteristics\n\nShape: The t-distribution is similar to the standard normal distribution (bell-shaped and symmetric around zero), but it has heavier tails. This means it is more prone to producing values that fall far from its mean.\nDegrees of Freedom (df): The shape of the t-distribution depends on the degrees of freedom, which is typically related to the sample size (df = n - 1 for a single sample t-test). As the degrees of freedom increase, the t-distribution approaches the standard normal distribution. For large sample sizes (df &gt; 30), the t-distribution and normal distribution are almost indistinguishable.\nMean and Variance: The mean of the t-distribution is 0. • The variance is greater than 1 and depends on the degrees of freedom. Specifically, the variance is for df &gt; 2 .\n\n\n\n6.2.2 Common uses\n\nConfidence intervals: The t-distribution is used to construct confidence intervals for the population mean when the population variance is unknown and the sample size is small.\nt-test: Used to compare the means of two groups (independent or paired samples) when the sample size is small and the population standard deviation is unknown.\n\nOne-sample t-test: Tests if the mean of a single sample is significantly different from a known value.\nTwo-sample t-test: Tests if the means of two independent groups are significantly different.\nPaired t-test: Tests if the means of two related groups (e.g., before and after measurements) are significantly different.\n\nRegression Analysis: In linear regression, t-test are used to determine whether the coefficients of the independent variables are significantly different from zero.\n\nExample:\n\nExample 1: \nImagine you have a small sample of 15 observations, and you want to test if the mean of this sample is different from a known value, say 50. Since the sample size is small, you would use the t-distribution to conduct this test, accounting for the fact that the true standard deviation of the population is unknown.\n\n\n\n6.2.3 \n例3-1 若某市1999年18岁男生身高服从均数为167.7cm，标准差为5.3cm的正态分布。从该正态分布N(167.7, 5.32)cm总体中随机抽样100次即共抽取样本g=100个，每次样本含量10人，计算得到每个样本的均数及标准差，数据以 .csv 格式保存，利用read_csv()函数导入R变量 height_sample 中。\n\nheight_sample &lt;- read_csv(\"datasets/ex04-01.csv\") \n\n#&gt; Rows: 100 Columns: 3\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (3): no, mean, sd\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(height_sample) |&gt; \n  kbl(align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n\n\nno\nmean\nsd\n\n\n\n\n1\n167.41\n2.74\n\n\n2\n165.56\n6.57\n\n\n3\n168.20\n5.36\n\n\n4\n166.67\n4.81\n\n\n5\n164.89\n5.41\n\n\n6\n166.36\n4.50",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#标准误和可信区间",
    "href": "ttest.html#标准误和可信区间",
    "title": "6  t-test",
    "section": "6.3 标准误和可信区间",
    "text": "6.3 标准误和可信区间\n\n6.3.1 单一总体均数的可信区间\n例3-2 计算例3-1中每个样本的标准误和可信区间\n\nmean  &lt;- height_sample$mean\nsd    &lt;- height_sample$sd\nlower_bound = vector(mode = \"double\", length = 100)\nupper_bound = vector(mode = \"double\", length = 100)\n\nfor(i in seq(1:100)){\n1  ttest &lt;- DescTools::TTestA(\n  mx = mean[i],\n  sx = sd[i],\n  nx = 10,\n  alternative = \"two.sided\",\n  mu = 167.7\n  )\n  ci &lt;- ttest$conf.int\n  lower_bound[i] &lt;- ci[1]\n  upper_bound[i] &lt;- ci[2]\n}\n\nheight_sample |&gt; \n  mutate(\n    se          = sd / sqrt(10),\n    lower_bound = lower_bound,\n    upper_bound = upper_bound\n  ) |&gt; \n  head()|&gt; \n  kbl(digits = 2, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\nTTestA()根据用户提供的统计量进行单个或两个样本 t 检验，而不是像t.test()中那样基于数据直接进行检验；此例是单样本，两样本类同，参见下例。\n\n\n\n\n\n\n\nno\nmean\nsd\nse\nlower_bound\nupper_bound\n\n\n\n\n1\n167.41\n2.74\n0.87\n165.45\n169.37\n\n\n2\n165.56\n6.57\n2.08\n160.86\n170.26\n\n\n3\n168.20\n5.36\n1.69\n164.37\n172.03\n\n\n4\n166.67\n4.81\n1.52\n163.23\n170.11\n\n\n5\n164.89\n5.41\n1.71\n161.02\n168.76\n\n\n6\n166.36\n4.50\n1.42\n163.14\n169.58\n\n\n\n\n\n\n\n\n\n6.3.2 两总体均数差的可信区间\n例3-3 61名患者随机分为两组，已知安慰剂组29例，试验组32例，治疗前安慰剂组IL-2的均数为20.1，标准差为7.02；试验组IL-2的均数为16.89，标准差为8.46。问两组治疗前基线的IL-2相差有多大？\n\nttest &lt;- DescTools::TTestA(\nmx = 20.1,\nmy = 16.89,\nsx = 7.02,\nsy = 8.46,\nnx = 29,\nny = 32,\nalternative = \"two.sided\"\n)\nci &lt;- ttest$conf.int |&gt; \n  round(digits = 2)\n\n因此，两组治疗前基线的IL-2总体均数之差的95%可信区间为(-0.76, 7.18)。",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-检验",
    "href": "ttest.html#t-检验",
    "title": "6  t-test",
    "section": "6.4 t 检验",
    "text": "6.4 t 检验\n计量资料的假设检验中，最常见、最简单的方法是 t 检验。\n\n6.4.1 单样本 t 检验\n例3-4 某医生测量了36名从事铅作业男性工人的血红蛋白含量，算得其均数为130.83g/L，标准差为25.74g/L。问从事铅作业工人的血红蛋白是否不同于正常成年男性平均值140g/L？\n\nread_csv(\"datasets/ex04-05.csv\", show_col_types = F) |&gt; \n  t.test(mu = 140) |&gt; \n1  broom::tidy() |&gt;\n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F)\n\n\n1\n\n把一个对象变成一个整齐的tibble，方便表的格式化输出\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n130.833\n-2.137\n0.04\n35\n122.124\n139.543\nOne Sample t-test\ntwo.sided\n\n\n\n\n\n\n\n\n\n6.4.2 Paired sample t test\n例3-5 为比较两种方法对乳酸饮料中脂肪含量测定结果是否不同，随机抽取了10份乳酸饮料制品，分别用脂肪酸水解法和哥特里－罗紫法测定其结果。问两法测定结果是否不同？\n\npaired &lt;- read_csv(\"datasets/ex04-06.csv\") \n\n#&gt; Rows: 10 Columns: 3\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (3): no, x1, x2\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nt.test(\n  x = paired$x1,\n  y = paired$x2,\n  paired = T\n) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.272\n7.926\n0\n9\n0.195\n0.35\nPaired t-test\ntwo.sided\n\n\n\n\n\n\n\n\n\n6.4.3 Two-sample t-test\nThe two-sample t-test (aka, the independent t-test) can be performed using base R functions without the need for additional packages.\n\n\n\n\n\n\nExample\n\n\n\n为研究国产四类新药阿卡波糖胶囊的降血糖效果，某医院用40名II型糖尿病病人进行同期随机对照试验。研究者将这些病人随机等分到试验组(用阿卡波糖胶囊)和对照组(用拜唐苹胶囊)，分别测得试验开始前和8周时的空腹血糖，算得空腹血糖下降值，能否认为该国产四类新药阿卡波糖胶囊与拜唐苹胶囊对空腹血糖的降糖效果不同？\n\n\n\ntwo_sample &lt;- read_csv(\"datasets/ex04-07.csv\")  \n\n#&gt; Rows: 20 Columns: 2\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (2): x1, x2\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nt.test(\n  x = two_sample$x1,\n  y = two_sample$x2,\n) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T) \n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.56\n2.065\n2.625\n-0.642\n0.525\n36.086\n-2.329\n1.209\nWelch Two Sample t-test\ntwo.sided\n\n\n\n\n\n\n\n\n\n6.4.4 Approximate t-test\n进行两小样本均数比较，若两总体方差不等，可采用近似 t 检验:\n例3-7 在上述例3-6国产四类新药阿卡波糖胶囊的降血糖效果研究中，测得用拜唐苹胶囊对照组20例患者和阿卡波糖胶囊试验组20例患者，其8周时糖化血红蛋白HbA1c (%)的下降值见 Table 6.1 。问使用两种不同药物的患者其HbA1c下降值是否相同？\n\n\n\n\nTable 6.1: 阿卡波糖胶囊组和拜唐苹胶囊组HbA1c (%)的下降值\n\n\n\n\n\n\n分组\n\\(n\\)\n\\(\\bar{X}\\)\n\\(S\\)\n\n\n\n\n试验组(阿卡波糖胶囊)\n20\n1.13\n0.70\n\n\n对照组(拜唐苹胶囊)\n20\n1.46\n1.36\n\n\n\n\n\n\n\n\n\nknitr::kable()成功将输出到html的表中的字符渲染为数学符号，其他包函数测试不成功\n\n本例中已知样本均数和方差，标准的t.test()通常用于直接分析数据集而非样本统计量，这里采用DescTools::TTestA()函数。经两样本方差齐性的\\(F\\)检验 (在 Section 6.5 中具体介绍)，两组的总体方差不等，故进行近似 t 检验。\n\nDescTools::TTestA(                              \n  mx = 1.13,\n  my = 1.46,\n  sx = 0.70,\n  sy = 1.36,\n  nx = 20,\n  ny = 20,\n  alternative = \"two.sided\",\n1  var.equal = F\n) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\nvar.equal，指示两个方差是否相等的逻辑变量。如果为FALSE，则使用Welch (或Satterthwaite) 法进行近似 t 检验\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.33\n1.13\n1.46\n-0.965\n0.343\n28.407\n-1.03\n0.37\nWelch Two Sample t-test\ntwo.sided",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#sec-homogeneity-test",
    "href": "ttest.html#sec-homogeneity-test",
    "title": "6  t-test",
    "section": "6.5 正态和方差齐性检验",
    "text": "6.5 正态和方差齐性检验\n\n6.5.1 正态性检验\n下面对例3-1中的100个样本均数进行正态性检验：\n（一）计算法\n下面分别采用stats::shapiro.test()和DescTools::ShapiroFranciaTest()进行正态性检验：\n\nx &lt;- height_sample |&gt; \n  select(mean) |&gt; \n1  unlist(use.names = F)\n  \n2stats::shapiro.test(x) |&gt;\n  broom::tidy() |&gt; \n  rbind(\n3    DescTools::ShapiroFranciaTest(x) |&gt;\n      broom::tidy()\n  ) |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\n注意：这里须加unlist(use.names = FALSE)，否则会报错\n\n2\n\nShapiro-Wilk方法\n\n3\n\nShapiro-Francia方法\n\n\n\n\n\n\n\nstatistic\np.value\nmethod\n\n\n\n\n0.994\n0.944\nShapiro-Wilk normality test\n\n\n0.993\n0.802\nShapiro-Francia normality test\n\n\n\n\n\n\n\nshapiro.test(x)要求x是数值型变量，所以虽然tibble中的mean是数值型，但不能直接传递给使用shapiro.test(x)，需加一个unlist(x, use.names = FALSE)操作，否则会报错，如下面代码块所示：\n\nx &lt;- height_samples |&gt; \n  select(mean) \n\n#&gt; Error in eval(expr, envir, enclos): object 'height_samples' not found\n\nstats::shapiro.test(x)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.99409, p-value = 0.9444\n\n\n（二）图示法\n图示法主要使用分位数图 (P-P图)和概率图 (Q-Q图)，其中以Q-Q图效率较高。如果分析的数据服从正态分布，则图上的数据点应分布在直线附近，否则数据点偏离直线较远。\n\nx &lt;- height_sample |&gt; \n  select(mean) |&gt; \n  unlist(use.names = F)\n\n\nstats::qqnorm(\n  x,\n  main = \"Q-Q图\",\n  xlab = \"理论分位数\",\n  ylab = \"样本分位数\",\n  datax = T\n) \nstats::qqline(\n  x,\n  datax = T\n)\n\n\n\n\n\n\n\n\n\n\n6.5.2 方差齐性检验\n对例3-6的数据，利用\\(F\\)检验判断两总体空腹血糖下降值的方差是否相等。这里利用DescTools::LeveneTest()进行方差齐性检验\n\ntb &lt;- two_sample |&gt; \n1  pivot_longer(\n    cols = everything(),\n    names_to = \"group\"\n  ) |&gt; \n  mutate(\n2    group = as.factor(group)\n  )\nDescTools::LeveneTest(tb$value, group = tb$group) |&gt; \n  broom::tidy() |&gt; \n  kbl(digits = 3, align = \"c\") |&gt;\n  kable_classic(full_width = F) |&gt; \n  row_spec(0, bold = T)\n\n\n1\n\n将原数据框进行拉长转换，以符合DescTools::LeveneTest()参数的要求\n\n2\n\n作为数据分组变量，需转换为因子类型，否则会输出警告\n\n\n\n\n\n\n\nstatistic\np.value\ndf\ndf.residual\n\n\n\n\n0.493\n0.487\n1\n38",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "anova.html",
    "href": "anova.html",
    "title": "7  Analysis of Variance",
    "section": "",
    "text": "7.1 Prerequisite\nlibrary(haven)\nlibrary(tidyverse)",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "anova.html#completely-randomized-design",
    "href": "anova.html#completely-randomized-design",
    "title": "7  Analysis of Variance",
    "section": "7.2 Completely randomized design",
    "text": "7.2 Completely randomized design\n\n\n\n\n\n\nExample\n\n\n\nTo evaluate the efficacy of xanomeline in subjects with mild to moderate Alzheimer’s disease, subjects were randomized equally to placebo, xanomeline low dose, or xanomeline high dose. Subjects applied 2 patches daily and were followed for a total of 26 weeks. Primary efficacy endpoints\n\n\n\n# haven::read_dta(\"datasets/例02-05.dta\") |&gt; \n#   write_csv(\"datasets/ex02-05.csv\")",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "anova.html#section",
    "href": "anova.html#section",
    "title": "7  Analysis of Variance",
    "section": "7.3 ",
    "text": "7.3",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "cox-regression.html",
    "href": "cox-regression.html",
    "title": "13  Cox regression",
    "section": "",
    "text": "Cox regression, also known as Cox proportional hazards regression, is a statistical method used to analyze the time until an event occurs, typically survival time. It is widely used in medical research to explore the relationship between the survival time of patients and one or more predictor variables. Unlike other models, Cox regression does not require assumptions about the baseline hazard function, making it a flexible tool for handling censored data where the exact time of the event may not be known for all subjects.",
    "crumbs": [
      "Basic methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Cox regression</span>"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "16  Quarto",
    "section": "",
    "text": "16.1 GitHub Action\n呈现和发布内容有几种不同的方法。下面，我们将提供一个使用 GitHub Actions 和 GitHub Pages 发布内容的指南。",
    "crumbs": [
      "Communication",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#github-action",
    "href": "quarto.html#github-action",
    "title": "16  Quarto",
    "section": "",
    "text": "16.1.1 执行代码\n如果你愿意，可以配置一个 GitHub Action 来执行 R 代码作为渲染的一部分。这虽然是最好的方法，但当在 GitHub Actions 等 CI 服务中执行代码时，请考虑以下要求:\n\n你需要在 CI 环境中重新配置所有依赖项（包括 R 以及所需的正确版本的包）。\n如果你的代码需要任何特殊权限（例如访问数据库或网络）， CI 服务器上也需要具备这些权限。\n你的项目可能包含无法轻易执行的文档（例如使用旧版包的几年前的博客文章）。这些文档可能需要单独启用冻结功能，以防止它们在 CI 上执行。\n\n\n\n16.1.2 先决条件\n确保代码可以在 GitHub Action 中执行的最佳方法是为项目使用 renv 虚拟环境。以下是一个完整的 GitHub Action 示例，它安装 R 和 renv.lock 中的包依赖项，然后执行代码并将输出渲染到 GitHub Pages：\n\n\n\n\n\n\nTip\n\n\n\n在 RStudio 左下窗口的 Terminal 选项卡中依次运行以下 Git 命令：\n\ngit remote add origin https://github.com/qbgaoo/r4ms.git\ngit branch -M main\ngit push -u origin main\n\n\n\n在 Quarto 项目中新建文本文件，命名为 publish.yml（当然也可以是其他命字），保存路径为 .github/workflows/publish.yml，在文件中添加如下内容：\non:\n  push:\n    branches: main\n  pull_request:\n    branches: main\n  # to be able to trigger a manual build\n  workflow_dispatch:\n  schedule:\n    # run every day at 11 PM\n    - cron: '0 23 * * *'\n\nname: Render and deploy Book to Github\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Install R\n        uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: '4.4.1'\n\n      - name: Install R Dependencies\n        uses: r-lib/actions/setup-renv@v2\n        with:\n          cache-version: 1\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n这是一个 GitHub Actions 工作流配置文件，保存后将文件提交到 GitHub中，触发文件中的工作流。",
    "crumbs": [
      "Communication",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "pilot-project.html",
    "href": "pilot-project.html",
    "title": "17  A case to analyze",
    "section": "",
    "text": "17.1 Datasets\nIn this book, we used publicly available CDISC pilot study data, which is accessible through the CDISC GitHub repository. To streamline the process, we have downloaded all the datasets from the repository and converted them from .xpt format to .sas7bdat format for ease of use and compatibility. Then we stored them in the data/adam/ folder within this project. Additionally, The dataset structure adheres to the CDISC Analysis Data Model (ADaM) standard.\nThe SDTM-ADaM Pilot Project datasets were created to demonstrate the process of converting clinical trial data into formats that comply with the Study Data Tabulation Model (SDTM) and Analysis Data Model (ADaM) standards, which are set by the Clinical Data Interchange Standards Consortium (CDISC). These datasets are used to test, validate, and illustrate how to implement CDISC standards in real-world scenarios, helping pharmaceutical companies and regulatory agencies like the FDA ensure data quality and consistency in clinical trials.\nlibrary(haven)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\n\nadsl |&gt; \n  select(ARM, ITTFL, EFFFL) |&gt; \n  filter(EFFFL == \"Y\") |&gt; \n  group_by(ARM) |&gt; \n  summarise(n = n())\n\n# A tibble: 3 × 2\n  ARM                      n\n  &lt;chr&gt;                &lt;int&gt;\n1 Placebo                 79\n2 Xanomeline High Dose    74\n3 Xanomeline Low Dose     81\nadsl |&gt; \n  glimpse()\n\nRows: 254\nColumns: 48\n$ STUDYID  &lt;chr&gt; \"CDISCPILOT01\", \"CDISCPILOT01\", \"CDISCPILOT01\", \"CDISCPILOT01…\n$ USUBJID  &lt;chr&gt; \"01-701-1015\", \"01-701-1023\", \"01-701-1028\", \"01-701-1033\", \"…\n$ SUBJID   &lt;chr&gt; \"1015\", \"1023\", \"1028\", \"1033\", \"1034\", \"1047\", \"1097\", \"1111…\n$ SITEID   &lt;chr&gt; \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\"…\n$ SITEGR1  &lt;chr&gt; \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\", \"701\"…\n$ ARM      &lt;chr&gt; \"Placebo\", \"Placebo\", \"Xanomeline High Dose\", \"Xanomeline Low…\n$ TRT01P   &lt;chr&gt; \"Placebo\", \"Placebo\", \"Xanomeline High Dose\", \"Xanomeline Low…\n$ TRT01PN  &lt;dbl&gt; 0, 0, 81, 54, 81, 0, 54, 54, 54, 0, 0, 81, 81, 81, 0, 81, 81,…\n$ TRT01A   &lt;chr&gt; \"Placebo\", \"Placebo\", \"Xanomeline High Dose\", \"Xanomeline Low…\n$ TRT01AN  &lt;dbl&gt; 0, 0, 81, 54, 81, 0, 54, 54, 54, 0, 0, 81, 81, 81, 0, 81, 81,…\n$ TRTSDT   &lt;date&gt; 2014-01-02, 2012-08-05, 2013-07-19, 2014-03-18, 2014-07-01, …\n$ TRTEDT   &lt;date&gt; 2014-07-02, 2012-09-01, 2014-01-14, 2014-03-31, 2014-12-30, …\n$ TRTDUR   &lt;dbl&gt; 182, 28, 180, 14, 183, 26, 190, 10, 55, 182, 183, 183, 38, 18…\n$ AVGDD    &lt;dbl&gt; 0.0, 0.0, 77.7, 54.0, 76.9, 0.0, 54.0, 54.0, 54.0, 0.0, 0.0, …\n$ CUMDOSE  &lt;dbl&gt; 0, 0, 13986, 756, 14067, 0, 10260, 540, 2970, 0, 0, 14121, 26…\n$ AGE      &lt;dbl&gt; 63, 64, 71, 74, 77, 85, 68, 81, 84, 52, 84, 81, 75, 57, 79, 5…\n$ AGEGR1   &lt;chr&gt; \"&lt;65\", \"&lt;65\", \"65-80\", \"65-80\", \"65-80\", \"&gt;80\", \"65-80\", \"&gt;80…\n$ AGEGR1N  &lt;dbl&gt; 1, 1, 2, 2, 2, 3, 2, 3, 3, 1, 3, 3, 2, 1, 2, 1, 2, 2, 2, 3, 2…\n$ AGEU     &lt;chr&gt; \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\", \"YEARS\"…\n$ RACE     &lt;chr&gt; \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\", \"WHITE\"…\n$ RACEN    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1…\n$ SEX      &lt;chr&gt; \"F\", \"M\", \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\", \"F\", \"…\n$ ETHNIC   &lt;chr&gt; \"HISPANIC OR LATINO\", \"HISPANIC OR LATINO\", \"NOT HISPANIC OR …\n$ SAFFL    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ ITTFL    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ EFFFL    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ COMP8FL  &lt;chr&gt; \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ COMP16FL &lt;chr&gt; \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"Y\", \"…\n$ COMP24FL &lt;chr&gt; \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"Y\", \"…\n$ DISCONFL &lt;chr&gt; \"\", \"Y\", \"\", \"Y\", \"\", \"Y\", \"\", \"Y\", \"Y\", \"\", \"\", \"\", \"Y\", \"\",…\n$ DSRAEFL  &lt;chr&gt; \"\", \"Y\", \"\", \"\", \"\", \"Y\", \"\", \"Y\", \"Y\", \"\", \"\", \"\", \"Y\", \"\", …\n$ DTHFL    &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ BMIBL    &lt;dbl&gt; 25.1, 30.4, 31.4, 28.8, 26.1, 30.4, 27.3, 23.9, 23.9, 21.9, 2…\n$ BMIBLGR1 &lt;chr&gt; \"25-&lt;30\", \"&gt;=30\", \"&gt;=30\", \"25-&lt;30\", \"25-&lt;30\", \"&gt;=30\", \"25-&lt;30…\n$ HEIGHTBL &lt;dbl&gt; 147.3, 162.6, 177.8, 175.3, 154.9, 148.6, 168.9, 158.2, 181.6…\n$ WEIGHTBL &lt;dbl&gt; 54.4, 80.3, 99.3, 88.5, 62.6, 67.1, 78.0, 59.9, 78.9, 71.2, 7…\n$ EDUCLVL  &lt;dbl&gt; 16, 14, 16, 12, 9, 8, 18, 22, 12, 14, 12, 10, 16, 15, 6, 16, …\n$ DISONSDT &lt;date&gt; 2010-04-30, 2006-03-11, 2009-12-16, 2009-08-02, 2011-09-29, …\n$ DURDIS   &lt;dbl&gt; 43.9, 76.4, 42.8, 55.3, 32.9, 42.0, 99.1, 40.7, 101.9, 44.2, …\n$ DURDSGR1 &lt;chr&gt; \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12\", \"&gt;=12…\n$ VISIT1DT &lt;date&gt; 2013-12-26, 2012-07-22, 2013-07-11, 2014-03-10, 2014-06-24, …\n$ RFSTDTC  &lt;chr&gt; \"2014-01-02\", \"2012-08-05\", \"2013-07-19\", \"2014-03-18\", \"2014…\n$ RFENDTC  &lt;chr&gt; \"2014-07-02\", \"2012-09-02\", \"2014-01-14\", \"2014-04-14\", \"2014…\n$ VISNUMEN &lt;dbl&gt; 12, 5, 12, 5, 12, 6, 12, 4, 8, 12, 12, 12, 7, 12, 12, 7, 4, 7…\n$ RFENDT   &lt;date&gt; 2014-07-02, 2012-09-02, 2014-01-14, 2014-04-14, 2014-12-30, …\n$ DCDECOD  &lt;chr&gt; \"COMPLETED\", \"ADVERSE EVENT\", \"COMPLETED\", \"STUDY TERMINATED …\n$ DCREASCD &lt;chr&gt; \"Completed\", \"Adverse Event\", \"Completed\", \"Sponsor Decision\"…\n$ MMSETOT  &lt;dbl&gt; 23, 23, 23, 23, 21, 23, 10, 23, 20, 20, 19, 21, 22, 21, 10, 1…\nglimpse() makes it possible to see every column in a data frame. It’s a little like str() applied to a data frame but it tries to show you as much data as possible.\nOnce you read data in, the first step usually involves transforming it in some way to make it easier to work with in the rest of your analysis. Firstly, we use janitor::clean_names() to turn all column names of data frame adsl into snake case.",
    "crumbs": [
      "Communication",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>A case to analyze</span>"
    ]
  },
  {
    "objectID": "basic-stat.html",
    "href": "basic-stat.html",
    "title": "Basic methods",
    "section": "",
    "text": "基本的医学统计方法涵盖了数据的收集、整理、描述、分析和解释，旨在帮助研究者理解疾病的发生、发展、治疗效果及健康状况的分布规律。以下是医学研究中常用的一些基本统计方法：\n\n1. 描述性统计\n\n频率分析：计算各类别或数值出现的频数和百分比。\n集中趋势测量：平均值、中位数和众数，用于描述数据的中心位置。\n离散程度测量：标准差、方差、四分位数间距和极差，反映数据的分散程度。\n\n\n\n2. 推断性统计\n\n参数检验：\n\nt检验：用于比较两组或几组独立或配对样本的均值差异，如学生t检验、配对t检验。\nANOVA（方差分析）：比较多个样本均值是否存在显著差异。\n\n非参数检验：\n\nMann-Whitney U检验（Wilcoxon秩和检验的两样本形式）：适用于连续数据但不符合正态分布的两组样本均值差异检验。\nKruskal-Wallis H检验：多组独立样本的中位数差异检验，适用于非正态分布数据。\n\n卡方检验（Chi-square test）：用于分析分类变量间的关系，如四格表检验。\n\n\n\n3. 回归分析\n\n线性回归：研究一个或多个自变量与一个连续因变量之间的线性关系。\n逻辑回归（Logistic Regression）：适用于因变量为二分类或多元分类的场合，用来估计事件发生概率。\n\n\n\n5. 随机化和抽样\n\n随机化：确保研究的组间可比性。\n抽样技术：包括简单随机抽样、分层抽样、整群抽样等，确保样本代表性。\n\n\n\n6. 误差与功效分析\n\n类型I和II错误的理解，以及统计功效分析，以确定研究设计是否足够强大以检测预期效应。\n\n选择适当的统计方法需依据研究目的、数据类型（定量或定性）、数据分布（正态与否）、样本大小等因素。理解这些基础统计概念和方法对于设计和解读医学研究至关重要。",
    "crumbs": [
      "Basic methods"
    ]
  }
]